{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32f50a7",
   "metadata": {},
   "source": [
    "# Transformer求解偏微分方程 - 简明教程\n",
    "\n",
    "本教程介绍如何使用Transformer架构求解偏微分方程(PDE)。\n",
    "\n",
    "## 目录\n",
    "1. [基础概念](#1-基础概念)\n",
    "2. [数据准备](#2-数据准备)\n",
    "3. [模型构建](#3-模型构建)\n",
    "4. [训练过程](#4-训练过程)\n",
    "5. [结果可视化](#5-结果可视化)\n",
    "6. [实战案例：热传导方程](#6-实战案例热传导方程)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae94bcd",
   "metadata": {},
   "source": [
    "## 1. 基础概念\n",
    "\n",
    "### 1.1 为什么用Transformer解PDE？\n",
    "\n",
    "**传统方法的局限**：\n",
    "- CNN局限于局部特征\n",
    "- RNN难以捕捉长距离依赖\n",
    "\n",
    "**Transformer的优势**：\n",
    "- ✅ 全局注意力机制：捕捉空间任意位置的关系\n",
    "- ✅ 并行计算：高效训练\n",
    "- ✅ 多尺度特征：自适应关注不同尺度\n",
    "- ✅ 灵活性：处理不规则网格\n",
    "\n",
    "### 1.2 核心思想\n",
    "\n",
    "将PDE求解转化为序列建模问题：\n",
    "\n",
    "```\n",
    "输入序列：空间点 (x₁, x₂, ..., xₙ) + 对应值 (u₁, u₂, ..., uₙ)\n",
    "         ↓\n",
    "    Transformer\n",
    "         ↓\n",
    "输出序列：预测值 (û₁, û₂, ..., ûₙ)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4454f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加项目路径\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f511ae3",
   "metadata": {},
   "source": [
    "## 2. 数据准备\n",
    "\n",
    "### 2.1 生成1D热传导方程数据\n",
    "\n",
    "考虑简单的1D热传导方程：\n",
    "$$\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}$$\n",
    "\n",
    "初始条件：$u(x, 0) = \\sin(\\pi x)$\n",
    "\n",
    "边界条件：$u(0, t) = u(1, t) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9375c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heat_equation_data(num_samples=1000, nx=64, nt=50, alpha=0.01):\n",
    "    \"\"\"\n",
    "    生成1D热传导方程数据\n",
    "    \n",
    "    参数:\n",
    "        num_samples: 样本数量\n",
    "        nx: 空间离散点数\n",
    "        nt: 时间步数\n",
    "        alpha: 热扩散系数\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, 1, nx)\n",
    "    t = np.linspace(0, 1, nt)\n",
    "    dx = x[1] - x[0]\n",
    "    dt = t[1] - t[0]\n",
    "    \n",
    "    # 确保数值稳定性\n",
    "    r = alpha * dt / dx**2\n",
    "    if r > 0.5:\n",
    "        print(f\"Warning: r = {r:.4f} > 0.5, may be unstable!\")\n",
    "    \n",
    "    data_input = []\n",
    "    data_output = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # 随机初始条件（多个正弦波的叠加）\n",
    "        n_modes = np.random.randint(1, 4)\n",
    "        u = np.zeros((nt, nx))\n",
    "        \n",
    "        for mode in range(1, n_modes + 1):\n",
    "            amp = np.random.uniform(0.5, 1.5)\n",
    "            u[0] += amp * np.sin(mode * np.pi * x)\n",
    "        \n",
    "        # 应用边界条件\n",
    "        u[:, 0] = 0\n",
    "        u[:, -1] = 0\n",
    "        \n",
    "        # 时间演化（显式差分格式）\n",
    "        for n in range(0, nt-1):\n",
    "            for i in range(1, nx-1):\n",
    "                u[n+1, i] = u[n, i] + r * (u[n, i+1] - 2*u[n, i] + u[n, i-1])\n",
    "        \n",
    "        data_input.append(u[0])  # 初始条件\n",
    "        data_output.append(u[-1])  # 最终状态\n",
    "    \n",
    "    return np.array(data_input), np.array(data_output), x\n",
    "\n",
    "# 生成数据\n",
    "print(\"生成训练数据...\")\n",
    "X_train, y_train, x_grid = generate_heat_equation_data(num_samples=800)\n",
    "X_test, y_test, _ = generate_heat_equation_data(num_samples=200)\n",
    "\n",
    "print(f\"训练集: {X_train.shape}, 测试集: {X_test.shape}\")\n",
    "\n",
    "# 可视化一些样本\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "for i in range(3):\n",
    "    axes[0, i].plot(x_grid, X_train[i], 'b-', linewidth=2)\n",
    "    axes[0, i].set_title(f'初始条件 (样本 {i+1})')\n",
    "    axes[0, i].set_xlabel('x')\n",
    "    axes[0, i].set_ylabel('u(x, 0)')\n",
    "    axes[0, i].grid(True)\n",
    "    \n",
    "    axes[1, i].plot(x_grid, y_train[i], 'r-', linewidth=2)\n",
    "    axes[1, i].set_title(f'最终状态 (样本 {i+1})')\n",
    "    axes[1, i].set_xlabel('x')\n",
    "    axes[1, i].set_ylabel('u(x, T)')\n",
    "    axes[1, i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227e4d3",
   "metadata": {},
   "source": [
    "### 2.2 创建PyTorch数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed420fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDEDataset(Dataset):\n",
    "    \"\"\"PDE数据集类\"\"\"\n",
    "    \n",
    "    def __init__(self, inputs, outputs, coords):\n",
    "        self.inputs = torch.FloatTensor(inputs).unsqueeze(-1)  # [N, seq_len, 1]\n",
    "        self.outputs = torch.FloatTensor(outputs).unsqueeze(-1)\n",
    "        self.coords = torch.FloatTensor(coords).unsqueeze(0).expand(len(inputs), -1, 1)  # [N, seq_len, 1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.coords[idx], self.outputs[idx]\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = PDEDataset(X_train, y_train, x_grid)\n",
    "test_dataset = PDEDataset(X_test, y_test, x_grid)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"训练批次数: {len(train_loader)}\")\n",
    "print(f\"测试批次数: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac9f5b",
   "metadata": {},
   "source": [
    "## 3. 模型构建\n",
    "\n",
    "### 3.1 位置编码（Positional Encoding）\n",
    "\n",
    "Transformer需要位置信息，我们使用正弦-余弦位置编码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82db004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsPositionalEncoding(nn.Module):\n",
    "    \"\"\"基于物理坐标的位置编码\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, coord_dim=1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.coord_dim = coord_dim\n",
    "        \n",
    "        # 坐标投影\n",
    "        self.coord_proj = nn.Linear(coord_dim, d_model)\n",
    "        \n",
    "        # 频率编码\n",
    "        self.freq_bands = nn.Parameter(torch.randn(d_model // 2, coord_dim))\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        \"\"\"\n",
    "        编码物理坐标\n",
    "        \n",
    "        参数:\n",
    "            coords: [batch_size, seq_len, coord_dim]\n",
    "        返回:\n",
    "            编码: [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        # 线性编码\n",
    "        linear_encoding = self.coord_proj(coords)\n",
    "        \n",
    "        # 频率编码\n",
    "        coords_expanded = coords.unsqueeze(-2)  # [B, L, 1, C]\n",
    "        freq_expanded = self.freq_bands.unsqueeze(0).unsqueeze(0)  # [1, 1, D/2, C]\n",
    "        \n",
    "        freqs = torch.sum(coords_expanded * freq_expanded, dim=-1)  # [B, L, D/2]\n",
    "        \n",
    "        sin_encoding = torch.sin(freqs)\n",
    "        cos_encoding = torch.cos(freqs)\n",
    "        \n",
    "        freq_encoding = torch.cat([sin_encoding, cos_encoding], dim=-1)\n",
    "        \n",
    "        return linear_encoding + freq_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6101f65",
   "metadata": {},
   "source": [
    "### 3.2 简单的Transformer模型\n",
    "\n",
    "构建一个轻量级的Transformer用于PDE求解："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePDETransformer(nn.Module):\n",
    "    \"\"\"简单的PDE求解Transformer\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=1, output_dim=1, d_model=128, nhead=4, \n",
    "                 num_layers=3, coord_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # 输入投影\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # 位置编码\n",
    "        self.pos_encoding = PhysicsPositionalEncoding(d_model, coord_dim)\n",
    "        \n",
    "        # Transformer编码器\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            dropout=0.1,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # 输出投影\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model // 2, output_dim)\n",
    "        )\n",
    "        \n",
    "        self._reset_parameters()\n",
    "    \n",
    "    def _reset_parameters(self):\n",
    "        \"\"\"初始化参数\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    def forward(self, x, coords):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        参数:\n",
    "            x: 输入场值 [batch_size, seq_len, input_dim]\n",
    "            coords: 空间坐标 [batch_size, seq_len, coord_dim]\n",
    "        返回:\n",
    "            输出场值 [batch_size, seq_len, output_dim]\n",
    "        \"\"\"\n",
    "        # 输入嵌入 + 位置编码\n",
    "        x = self.input_proj(x) + self.pos_encoding(coords)\n",
    "        \n",
    "        # Transformer\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # 输出投影\n",
    "        return self.output_proj(x)\n",
    "\n",
    "# 创建模型\n",
    "model = SimplePDETransformer(\n",
    "    input_dim=1,\n",
    "    output_dim=1,\n",
    "    d_model=128,\n",
    "    nhead=4,\n",
    "    num_layers=4,\n",
    "    coord_dim=1\n",
    ").to(device)\n",
    "\n",
    "# 统计参数量\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\n模型参数量: {num_params:,}\")\n",
    "print(f\"\\n模型结构:\\n{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd460f",
   "metadata": {},
   "source": [
    "## 4. 训练过程\n",
    "\n",
    "### 4.1 定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e17528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 优化器\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)\n",
    "\n",
    "print(\"优化器和损失函数已配置\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6b84e",
   "metadata": {},
   "source": [
    "### 4.2 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"训练一个epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for inputs, coords, targets in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        coords = coords.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(inputs, coords)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"评估模型\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, coords, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            coords = coords.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs, coords)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# 训练\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "print(\"开始训练...\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'best_transformer_model.pth')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "              f\"Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}, \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "print(f\"\\n训练完成! 最佳测试损失: {best_test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64059c",
   "metadata": {},
   "source": [
    "### 4.3 训练曲线可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "plt.plot(test_losses, label='Test Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training and Test Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(train_losses, label='Train Loss', linewidth=2)\n",
    "plt.semilogy(test_losses, label='Test Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss (log scale)', fontsize=12)\n",
    "plt.title('Training and Test Loss (Log Scale)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77042a60",
   "metadata": {},
   "source": [
    "## 5. 结果可视化\n",
    "\n",
    "### 5.1 预测vs真实值对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef17d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('best_transformer_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 获取一些测试样本\n",
    "num_vis = 6\n",
    "indices = np.random.choice(len(X_test), num_vis, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, num_vis//3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(indices):\n",
    "        # 准备输入\n",
    "        input_data = torch.FloatTensor(X_test[idx:idx+1]).unsqueeze(-1).to(device)\n",
    "        coords_data = torch.FloatTensor(x_grid).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        \n",
    "        # 预测\n",
    "        output = model(input_data, coords_data)\n",
    "        prediction = output.cpu().numpy()[0, :, 0]\n",
    "        \n",
    "        # 真实值\n",
    "        true_output = y_test[idx]\n",
    "        \n",
    "        # 绘图\n",
    "        axes[i].plot(x_grid, X_test[idx], 'b--', linewidth=2, label='初始条件', alpha=0.6)\n",
    "        axes[i].plot(x_grid, true_output, 'g-', linewidth=2, label='真实值')\n",
    "        axes[i].plot(x_grid, prediction, 'r--', linewidth=2, label='预测值')\n",
    "        \n",
    "        # 计算相对误差\n",
    "        rel_error = np.linalg.norm(prediction - true_output) / np.linalg.norm(true_output)\n",
    "        \n",
    "        axes[i].set_title(f'样本 {idx+1} (相对误差: {rel_error:.4f})', fontsize=11, fontweight='bold')\n",
    "        axes[i].set_xlabel('x', fontsize=10)\n",
    "        axes[i].set_ylabel('u', fontsize=10)\n",
    "        axes[i].legend(fontsize=9, loc='upper right')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c27ceb",
   "metadata": {},
   "source": [
    "### 5.2 误差分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295126e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算所有测试样本的误差\n",
    "relative_errors = []\n",
    "absolute_errors = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        input_data = torch.FloatTensor(X_test[i:i+1]).unsqueeze(-1).to(device)\n",
    "        coords_data = torch.FloatTensor(x_grid).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        \n",
    "        output = model(input_data, coords_data)\n",
    "        prediction = output.cpu().numpy()[0, :, 0]\n",
    "        true_output = y_test[i]\n",
    "        \n",
    "        abs_error = np.linalg.norm(prediction - true_output)\n",
    "        rel_error = abs_error / np.linalg.norm(true_output)\n",
    "        \n",
    "        absolute_errors.append(abs_error)\n",
    "        relative_errors.append(rel_error)\n",
    "\n",
    "# 可视化误差分布\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 相对误差直方图\n",
    "axes[0].hist(relative_errors, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(np.mean(relative_errors), color='r', linestyle='--', \n",
    "                linewidth=2, label=f'平均值: {np.mean(relative_errors):.4f}')\n",
    "axes[0].set_xlabel('相对误差', fontsize=12)\n",
    "axes[0].set_ylabel('频数', fontsize=12)\n",
    "axes[0].set_title('相对误差分布', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 绝对误差直方图\n",
    "axes[1].hist(absolute_errors, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].axvline(np.mean(absolute_errors), color='r', linestyle='--', \n",
    "                linewidth=2, label=f'平均值: {np.mean(absolute_errors):.4f}')\n",
    "axes[1].set_xlabel('绝对误差', fontsize=12)\n",
    "axes[1].set_ylabel('频数', fontsize=12)\n",
    "axes[1].set_title('绝对误差分布', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 误差散点图\n",
    "axes[2].scatter(absolute_errors, relative_errors, alpha=0.5, s=20)\n",
    "axes[2].set_xlabel('绝对误差', fontsize=12)\n",
    "axes[2].set_ylabel('相对误差', fontsize=12)\n",
    "axes[2].set_title('绝对误差 vs 相对误差', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印统计信息\n",
    "print(\"\\n=== 误差统计 ===\")\n",
    "print(f\"相对误差 - 平均: {np.mean(relative_errors):.6f}, 标准差: {np.std(relative_errors):.6f}\")\n",
    "print(f\"相对误差 - 最小: {np.min(relative_errors):.6f}, 最大: {np.max(relative_errors):.6f}\")\n",
    "print(f\"绝对误差 - 平均: {np.mean(absolute_errors):.6f}, 标准差: {np.std(absolute_errors):.6f}\")\n",
    "print(f\"绝对误差 - 最小: {np.min(absolute_errors):.6f}, 最大: {np.max(absolute_errors):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e96471",
   "metadata": {},
   "source": [
    "## 6. 实战案例：热传导方程\n",
    "\n",
    "### 6.1 时间演化可视化\n",
    "\n",
    "让我们看看Transformer如何捕捉热传导的时间演化过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27669a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_evolution(initial_condition, x_grid, nt=50, alpha=0.01):\n",
    "    \"\"\"生成时间演化序列\"\"\"\n",
    "    nx = len(x_grid)\n",
    "    dx = x_grid[1] - x_grid[0]\n",
    "    dt = 1.0 / (nt - 1)\n",
    "    r = alpha * dt / dx**2\n",
    "    \n",
    "    u = np.zeros((nt, nx))\n",
    "    u[0] = initial_condition\n",
    "    u[:, 0] = 0\n",
    "    u[:, -1] = 0\n",
    "    \n",
    "    for n in range(0, nt-1):\n",
    "        for i in range(1, nx-1):\n",
    "            u[n+1, i] = u[n, i] + r * (u[n, i+1] - 2*u[n, i] + u[n, i-1])\n",
    "    \n",
    "    return u\n",
    "\n",
    "# 选择一个初始条件\n",
    "test_idx = 0\n",
    "initial = X_test[test_idx]\n",
    "true_evolution = generate_time_evolution(initial, x_grid)\n",
    "\n",
    "# 使用模型进行多步预测（这里我们简化为直接预测最终状态）\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    input_data = torch.FloatTensor(initial).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "    coords_data = torch.FloatTensor(x_grid).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "    final_pred = model(input_data, coords_data).cpu().numpy()[0, :, 0]\n",
    "\n",
    "# 可视化\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# 真实的时间演化\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "time_steps_to_show = [0, 10, 20, 30, 40, 49]\n",
    "for t_idx in time_steps_to_show:\n",
    "    ax1.plot(x_grid, true_evolution[t_idx], linewidth=2, \n",
    "             label=f't = {t_idx/(len(true_evolution)-1):.2f}')\n",
    "ax1.set_xlabel('x', fontsize=12)\n",
    "ax1.set_ylabel('u(x, t)', fontsize=12)\n",
    "ax1.set_title('真实的时间演化', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 热力图\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "im = ax2.imshow(true_evolution.T, aspect='auto', origin='lower', \n",
    "                extent=[0, 1, 0, 1], cmap='hot')\n",
    "ax2.set_xlabel('时间 t', fontsize=12)\n",
    "ax2.set_ylabel('空间 x', fontsize=12)\n",
    "ax2.set_title('热传导时空演化', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax2, label='u(x, t)')\n",
    "\n",
    "# 初始 vs 最终状态对比\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax3.plot(x_grid, initial, 'b-', linewidth=2, label='初始条件')\n",
    "ax3.plot(x_grid, true_evolution[-1], 'g-', linewidth=2, label='真实最终状态')\n",
    "ax3.plot(x_grid, final_pred, 'r--', linewidth=2, label='预测最终状态')\n",
    "ax3.set_xlabel('x', fontsize=12)\n",
    "ax3.set_ylabel('u', fontsize=12)\n",
    "ax3.set_title('初始 vs 最终状态', fontsize=14, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 误差分布\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "error = np.abs(final_pred - true_evolution[-1])\n",
    "ax4.plot(x_grid, error, 'r-', linewidth=2)\n",
    "ax4.fill_between(x_grid, 0, error, alpha=0.3, color='red')\n",
    "ax4.set_xlabel('x', fontsize=12)\n",
    "ax4.set_ylabel('绝对误差', fontsize=12)\n",
    "ax4.set_title(f'预测误差分布 (最大误差: {np.max(error):.4f})', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097135e3",
   "metadata": {},
   "source": [
    "## 7. 总结与展望\n",
    "\n",
    "### 7.1 本教程学到的内容\n",
    "\n",
    "✅ **基础概念**：\n",
    "- Transformer的核心原理：自注意力机制\n",
    "- 位置编码在PDE中的应用\n",
    "- 序列建模思想\n",
    "\n",
    "✅ **实践技能**：\n",
    "- 数据准备与预处理\n",
    "- 构建适用于PDE的Transformer模型\n",
    "- 训练与评估流程\n",
    "- 结果可视化与误差分析\n",
    "\n",
    "✅ **应用案例**：\n",
    "- 1D热传导方程求解\n",
    "- 时间演化预测\n",
    "\n",
    "### 7.2 进阶方向\n",
    "\n",
    "🚀 **模型改进**：\n",
    "- 尝试Vision Transformer处理2D/3D问题\n",
    "- 引入物理信息约束（Physics-Informed Transformer）\n",
    "- 多尺度注意力机制\n",
    "- 图Transformer处理不规则网格\n",
    "\n",
    "🚀 **应用扩展**：\n",
    "- Navier-Stokes方程（流体力学）\n",
    "- Maxwell方程（电磁学）\n",
    "- Schrödinger方程（量子力学）\n",
    "- 多物理场耦合问题\n",
    "\n",
    "🚀 **性能优化**：\n",
    "- 混合精度训练\n",
    "- 模型剪枝与量化\n",
    "- 分布式训练\n",
    "- 迁移学习\n",
    "\n",
    "### 7.3 相关资源\n",
    "\n",
    "📚 **论文**：\n",
    "- \"Choose a Transformer: Fourier or Galerkin\" (NeurIPS 2021)\n",
    "- \"Transformer for Partial Differential Equations' Operator Learning\" (2022)\n",
    "- \"Physics-Informed Neural Networks: A Deep Learning Framework\" (2019)\n",
    "\n",
    "💻 **代码库**：\n",
    "- 本项目：`AI4CFD/Transformer/`\n",
    "- PyTorch官方文档：https://pytorch.org/docs/stable/nn.html#transformer\n",
    "- Hugging Face Transformers：https://huggingface.co/transformers/\n",
    "\n",
    "---\n",
    "\n",
    "**感谢使用本教程！如有问题，欢迎提Issue或PR。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d3ac2",
   "metadata": {},
   "source": [
    "## 附录：模型保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ec086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存完整模型\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'best_test_loss': best_test_loss,\n",
    "}, 'transformer_checkpoint.pth')\n",
    "\n",
    "print(\"模型已保存到 transformer_checkpoint.pth\")\n",
    "\n",
    "# 加载模型示例\n",
    "# checkpoint = torch.load('transformer_checkpoint.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# print(f\"模型已加载，最佳测试损失: {checkpoint['best_test_loss']:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
