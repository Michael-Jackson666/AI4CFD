{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32f50a7",
   "metadata": {},
   "source": [
    "# Transformeræ±‚è§£åå¾®åˆ†æ–¹ç¨‹ - ç®€æ˜æ•™ç¨‹\n",
    "\n",
    "æœ¬æ•™ç¨‹ä»‹ç»å¦‚ä½•ä½¿ç”¨Transformeræ¶æ„æ±‚è§£åå¾®åˆ†æ–¹ç¨‹(PDE)ã€‚\n",
    "\n",
    "## ç›®å½•\n",
    "1. [åŸºç¡€æ¦‚å¿µ](#1-åŸºç¡€æ¦‚å¿µ)\n",
    "2. [æ•°æ®å‡†å¤‡](#2-æ•°æ®å‡†å¤‡)\n",
    "3. [æ¨¡å‹æ„å»º](#3-æ¨¡å‹æ„å»º)\n",
    "4. [è®­ç»ƒè¿‡ç¨‹](#4-è®­ç»ƒè¿‡ç¨‹)\n",
    "5. [ç»“æœå¯è§†åŒ–](#5-ç»“æœå¯è§†åŒ–)\n",
    "6. [å®æˆ˜æ¡ˆä¾‹ï¼šçƒ­ä¼ å¯¼æ–¹ç¨‹](#6-å®æˆ˜æ¡ˆä¾‹çƒ­ä¼ å¯¼æ–¹ç¨‹)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae94bcd",
   "metadata": {},
   "source": [
    "## 1. åŸºç¡€æ¦‚å¿µ\n",
    "\n",
    "### 1.1 ä¸ºä»€ä¹ˆç”¨Transformerè§£PDEï¼Ÿ\n",
    "\n",
    "**ä¼ ç»Ÿæ–¹æ³•çš„å±€é™**ï¼š\n",
    "- CNNå±€é™äºå±€éƒ¨ç‰¹å¾\n",
    "- RNNéš¾ä»¥æ•æ‰é•¿è·ç¦»ä¾èµ–\n",
    "\n",
    "**Transformerçš„ä¼˜åŠ¿**ï¼š\n",
    "- âœ… å…¨å±€æ³¨æ„åŠ›æœºåˆ¶ï¼šæ•æ‰ç©ºé—´ä»»æ„ä½ç½®çš„å…³ç³»\n",
    "- âœ… å¹¶è¡Œè®¡ç®—ï¼šé«˜æ•ˆè®­ç»ƒ\n",
    "- âœ… å¤šå°ºåº¦ç‰¹å¾ï¼šè‡ªé€‚åº”å…³æ³¨ä¸åŒå°ºåº¦\n",
    "- âœ… çµæ´»æ€§ï¼šå¤„ç†ä¸è§„åˆ™ç½‘æ ¼\n",
    "\n",
    "### 1.2 æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "å°†PDEæ±‚è§£è½¬åŒ–ä¸ºåºåˆ—å»ºæ¨¡é—®é¢˜ï¼š\n",
    "\n",
    "```\n",
    "è¾“å…¥åºåˆ—ï¼šç©ºé—´ç‚¹ (xâ‚, xâ‚‚, ..., xâ‚™) + å¯¹åº”å€¼ (uâ‚, uâ‚‚, ..., uâ‚™)\n",
    "         â†“\n",
    "    Transformer\n",
    "         â†“\n",
    "è¾“å‡ºåºåˆ—ï¼šé¢„æµ‹å€¼ (Ã»â‚, Ã»â‚‚, ..., Ã»â‚™)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4454f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# è®¾ç½®è®¾å¤‡\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f511ae3",
   "metadata": {},
   "source": [
    "## 2. æ•°æ®å‡†å¤‡\n",
    "\n",
    "### 2.1 ç”Ÿæˆ1Dçƒ­ä¼ å¯¼æ–¹ç¨‹æ•°æ®\n",
    "\n",
    "è€ƒè™‘ç®€å•çš„1Dçƒ­ä¼ å¯¼æ–¹ç¨‹ï¼š\n",
    "$$\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}$$\n",
    "\n",
    "åˆå§‹æ¡ä»¶ï¼š$u(x, 0) = \\sin(\\pi x)$\n",
    "\n",
    "è¾¹ç•Œæ¡ä»¶ï¼š$u(0, t) = u(1, t) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9375c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heat_equation_data(num_samples=1000, nx=64, nt=50, alpha=0.01):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆ1Dçƒ­ä¼ å¯¼æ–¹ç¨‹æ•°æ®\n",
    "    \n",
    "    å‚æ•°:\n",
    "        num_samples: æ ·æœ¬æ•°é‡\n",
    "        nx: ç©ºé—´ç¦»æ•£ç‚¹æ•°\n",
    "        nt: æ—¶é—´æ­¥æ•°\n",
    "        alpha: çƒ­æ‰©æ•£ç³»æ•°\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, 1, nx)\n",
    "    t = np.linspace(0, 1, nt)\n",
    "    dx = x[1] - x[0]\n",
    "    dt = t[1] - t[0]\n",
    "    \n",
    "    # ç¡®ä¿æ•°å€¼ç¨³å®šæ€§\n",
    "    r = alpha * dt / dx**2\n",
    "    if r > 0.5:\n",
    "        print(f\"Warning: r = {r:.4f} > 0.5, may be unstable!\")\n",
    "    \n",
    "    data_input = []\n",
    "    data_output = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # éšæœºåˆå§‹æ¡ä»¶ï¼ˆå¤šä¸ªæ­£å¼¦æ³¢çš„å åŠ ï¼‰\n",
    "        n_modes = np.random.randint(1, 4)\n",
    "        u = np.zeros((nt, nx))\n",
    "        \n",
    "        for mode in range(1, n_modes + 1):\n",
    "            amp = np.random.uniform(0.5, 1.5)\n",
    "            u[0] += amp * np.sin(mode * np.pi * x)\n",
    "        \n",
    "        # åº”ç”¨è¾¹ç•Œæ¡ä»¶\n",
    "        u[:, 0] = 0\n",
    "        u[:, -1] = 0\n",
    "        \n",
    "        # æ—¶é—´æ¼”åŒ–ï¼ˆæ˜¾å¼å·®åˆ†æ ¼å¼ï¼‰\n",
    "        for n in range(0, nt-1):\n",
    "            for i in range(1, nx-1):\n",
    "                u[n+1, i] = u[n, i] + r * (u[n, i+1] - 2*u[n, i] + u[n, i-1])\n",
    "        \n",
    "        data_input.append(u[0])  # åˆå§‹æ¡ä»¶\n",
    "        data_output.append(u[-1])  # æœ€ç»ˆçŠ¶æ€\n",
    "    \n",
    "    return np.array(data_input), np.array(data_output), x\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "print(\"ç”Ÿæˆè®­ç»ƒæ•°æ®...\")\n",
    "X_train, y_train, x_grid = generate_heat_equation_data(num_samples=800)\n",
    "X_test, y_test, _ = generate_heat_equation_data(num_samples=200)\n",
    "\n",
    "print(f\"è®­ç»ƒé›†: {X_train.shape}, æµ‹è¯•é›†: {X_test.shape}\")\n",
    "\n",
    "# å¯è§†åŒ–ä¸€äº›æ ·æœ¬\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "for i in range(3):\n",
    "    axes[0, i].plot(x_grid, X_train[i], 'b-', linewidth=2)\n",
    "    axes[0, i].set_title(f'åˆå§‹æ¡ä»¶ (æ ·æœ¬ {i+1})')\n",
    "    axes[0, i].set_xlabel('x')\n",
    "    axes[0, i].set_ylabel('u(x, 0)')\n",
    "    axes[0, i].grid(True)\n",
    "    \n",
    "    axes[1, i].plot(x_grid, y_train[i], 'r-', linewidth=2)\n",
    "    axes[1, i].set_title(f'æœ€ç»ˆçŠ¶æ€ (æ ·æœ¬ {i+1})')\n",
    "    axes[1, i].set_xlabel('x')\n",
    "    axes[1, i].set_ylabel('u(x, T)')\n",
    "    axes[1, i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227e4d3",
   "metadata": {},
   "source": [
    "### 2.2 åˆ›å»ºPyTorchæ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed420fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDEDataset(Dataset):\n",
    "    \"\"\"PDEæ•°æ®é›†ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, inputs, outputs, coords):\n",
    "        self.inputs = torch.FloatTensor(inputs).unsqueeze(-1)  # [N, seq_len, 1]\n",
    "        self.outputs = torch.FloatTensor(outputs).unsqueeze(-1)\n",
    "        self.coords = torch.FloatTensor(coords).unsqueeze(0).expand(len(inputs), -1, 1)  # [N, seq_len, 1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.coords[idx], self.outputs[idx]\n",
    "\n",
    "# åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "train_dataset = PDEDataset(X_train, y_train, x_grid)\n",
    "test_dataset = PDEDataset(X_test, y_test, x_grid)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}\")\n",
    "print(f\"æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac9f5b",
   "metadata": {},
   "source": [
    "## 3. æ¨¡å‹æ„å»º\n",
    "\n",
    "### 3.1 ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰\n",
    "\n",
    "Transformeréœ€è¦ä½ç½®ä¿¡æ¯ï¼Œæˆ‘ä»¬ä½¿ç”¨æ­£å¼¦-ä½™å¼¦ä½ç½®ç¼–ç ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82db004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsPositionalEncoding(nn.Module):\n",
    "    \"\"\"åŸºäºç‰©ç†åæ ‡çš„ä½ç½®ç¼–ç \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, coord_dim=1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.coord_dim = coord_dim\n",
    "        \n",
    "        # åæ ‡æŠ•å½±\n",
    "        self.coord_proj = nn.Linear(coord_dim, d_model)\n",
    "        \n",
    "        # é¢‘ç‡ç¼–ç \n",
    "        self.freq_bands = nn.Parameter(torch.randn(d_model // 2, coord_dim))\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        \"\"\"\n",
    "        ç¼–ç ç‰©ç†åæ ‡\n",
    "        \n",
    "        å‚æ•°:\n",
    "            coords: [batch_size, seq_len, coord_dim]\n",
    "        è¿”å›:\n",
    "            ç¼–ç : [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        # çº¿æ€§ç¼–ç \n",
    "        linear_encoding = self.coord_proj(coords)\n",
    "        \n",
    "        # é¢‘ç‡ç¼–ç \n",
    "        coords_expanded = coords.unsqueeze(-2)  # [B, L, 1, C]\n",
    "        freq_expanded = self.freq_bands.unsqueeze(0).unsqueeze(0)  # [1, 1, D/2, C]\n",
    "        \n",
    "        freqs = torch.sum(coords_expanded * freq_expanded, dim=-1)  # [B, L, D/2]\n",
    "        \n",
    "        sin_encoding = torch.sin(freqs)\n",
    "        cos_encoding = torch.cos(freqs)\n",
    "        \n",
    "        freq_encoding = torch.cat([sin_encoding, cos_encoding], dim=-1)\n",
    "        \n",
    "        return linear_encoding + freq_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6101f65",
   "metadata": {},
   "source": [
    "### 3.2 ç®€å•çš„Transformeræ¨¡å‹\n",
    "\n",
    "æ„å»ºä¸€ä¸ªè½»é‡çº§çš„Transformerç”¨äºPDEæ±‚è§£ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePDETransformer(nn.Module):\n",
    "    \"\"\"ç®€å•çš„PDEæ±‚è§£Transformer\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=1, output_dim=1, d_model=128, nhead=4, \n",
    "                 num_layers=3, coord_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # è¾“å…¥æŠ•å½±\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # ä½ç½®ç¼–ç \n",
    "        self.pos_encoding = PhysicsPositionalEncoding(d_model, coord_dim)\n",
    "        \n",
    "        # Transformerç¼–ç å™¨\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            dropout=0.1,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # è¾“å‡ºæŠ•å½±\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model // 2, output_dim)\n",
    "        )\n",
    "        \n",
    "        self._reset_parameters()\n",
    "    \n",
    "    def _reset_parameters(self):\n",
    "        \"\"\"åˆå§‹åŒ–å‚æ•°\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    def forward(self, x, coords):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        å‚æ•°:\n",
    "            x: è¾“å…¥åœºå€¼ [batch_size, seq_len, input_dim]\n",
    "            coords: ç©ºé—´åæ ‡ [batch_size, seq_len, coord_dim]\n",
    "        è¿”å›:\n",
    "            è¾“å‡ºåœºå€¼ [batch_size, seq_len, output_dim]\n",
    "        \"\"\"\n",
    "        # è¾“å…¥åµŒå…¥ + ä½ç½®ç¼–ç \n",
    "        x = self.input_proj(x) + self.pos_encoding(coords)\n",
    "        \n",
    "        # Transformer\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # è¾“å‡ºæŠ•å½±\n",
    "        return self.output_proj(x)\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model = SimplePDETransformer(\n",
    "    input_dim=1,\n",
    "    output_dim=1,\n",
    "    d_model=128,\n",
    "    nhead=4,\n",
    "    num_layers=4,\n",
    "    coord_dim=1\n",
    ").to(device)\n",
    "\n",
    "# ç»Ÿè®¡å‚æ•°é‡\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\næ¨¡å‹å‚æ•°é‡: {num_params:,}\")\n",
    "print(f\"\\næ¨¡å‹ç»“æ„:\\n{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd460f",
   "metadata": {},
   "source": [
    "## 4. è®­ç»ƒè¿‡ç¨‹\n",
    "\n",
    "### 4.1 å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e17528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸå¤±å‡½æ•°\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# ä¼˜åŒ–å™¨\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)\n",
    "\n",
    "print(\"ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°å·²é…ç½®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6b84e",
   "metadata": {},
   "source": [
    "### 4.2 è®­ç»ƒå¾ªç¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for inputs, coords, targets in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        coords = coords.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        outputs = model(inputs, coords)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # åå‘ä¼ æ’­\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # æ¢¯åº¦è£å‰ª\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"è¯„ä¼°æ¨¡å‹\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, coords, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            coords = coords.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs, coords)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# è®­ç»ƒ\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "print(\"å¼€å§‹è®­ç»ƒ...\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    # æ›´æ–°å­¦ä¹ ç‡\n",
    "    scheduler.step()\n",
    "    \n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'best_transformer_model.pth')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "              f\"Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}, \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "print(f\"\\nè®­ç»ƒå®Œæˆ! æœ€ä½³æµ‹è¯•æŸå¤±: {best_test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64059c",
   "metadata": {},
   "source": [
    "### 4.3 è®­ç»ƒæ›²çº¿å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "plt.plot(test_losses, label='Test Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training and Test Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(train_losses, label='Train Loss', linewidth=2)\n",
    "plt.semilogy(test_losses, label='Test Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss (log scale)', fontsize=12)\n",
    "plt.title('Training and Test Loss (Log Scale)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77042a60",
   "metadata": {},
   "source": [
    "## 5. ç»“æœå¯è§†åŒ–\n",
    "\n",
    "### 5.1 é¢„æµ‹vsçœŸå®å€¼å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef17d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æœ€ä½³æ¨¡å‹\n",
    "model.load_state_dict(torch.load('best_transformer_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# è·å–ä¸€äº›æµ‹è¯•æ ·æœ¬\n",
    "num_vis = 6\n",
    "indices = np.random.choice(len(X_test), num_vis, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, num_vis//3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(indices):\n",
    "        # å‡†å¤‡è¾“å…¥\n",
    "        input_data = torch.FloatTensor(X_test[idx:idx+1]).unsqueeze(-1).to(device)\n",
    "        coords_data = torch.FloatTensor(x_grid).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        \n",
    "        # é¢„æµ‹\n",
    "        output = model(input_data, coords_data)\n",
    "        prediction = output.cpu().numpy()[0, :, 0]\n",
    "        \n",
    "        # çœŸå®å€¼\n",
    "        true_output = y_test[idx]\n",
    "        \n",
    "        # ç»˜å›¾\n",
    "        axes[i].plot(x_grid, X_test[idx], 'b--', linewidth=2, label='åˆå§‹æ¡ä»¶', alpha=0.6)\n",
    "        axes[i].plot(x_grid, true_output, 'g-', linewidth=2, label='çœŸå®å€¼')\n",
    "        axes[i].plot(x_grid, prediction, 'r--', linewidth=2, label='é¢„æµ‹å€¼')\n",
    "        \n",
    "        # è®¡ç®—ç›¸å¯¹è¯¯å·®\n",
    "        rel_error = np.linalg.norm(prediction - true_output) / np.linalg.norm(true_output)\n",
    "        \n",
    "        axes[i].set_title(f'æ ·æœ¬ {idx+1} (ç›¸å¯¹è¯¯å·®: {rel_error:.4f})', fontsize=11, fontweight='bold')\n",
    "        axes[i].set_xlabel('x', fontsize=10)\n",
    "        axes[i].set_ylabel('u', fontsize=10)\n",
    "        axes[i].legend(fontsize=9, loc='upper right')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c27ceb",
   "metadata": {},
   "source": [
    "### 5.2 è¯¯å·®åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295126e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—æ‰€æœ‰æµ‹è¯•æ ·æœ¬çš„è¯¯å·®\n",
    "relative_errors = []\n",
    "absolute_errors = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        input_data = torch.FloatTensor(X_test[i:i+1]).unsqueeze(-1).to(device)\n",
    "        coords_data = torch.FloatTensor(x_grid).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        \n",
    "        output = model(input_data, coords_data)\n",
    "        prediction = output.cpu().numpy()[0, :, 0]\n",
    "        true_output = y_test[i]\n",
    "        \n",
    "        abs_error = np.linalg.norm(prediction - true_output)\n",
    "        rel_error = abs_error / np.linalg.norm(true_output)\n",
    "        \n",
    "        absolute_errors.append(abs_error)\n",
    "        relative_errors.append(rel_error)\n",
    "\n",
    "# å¯è§†åŒ–è¯¯å·®åˆ†å¸ƒ\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# ç›¸å¯¹è¯¯å·®ç›´æ–¹å›¾\n",
    "axes[0].hist(relative_errors, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(np.mean(relative_errors), color='r', linestyle='--', \n",
    "                linewidth=2, label=f'å¹³å‡å€¼: {np.mean(relative_errors):.4f}')\n",
    "axes[0].set_xlabel('ç›¸å¯¹è¯¯å·®', fontsize=12)\n",
    "axes[0].set_ylabel('é¢‘æ•°', fontsize=12)\n",
    "axes[0].set_title('ç›¸å¯¹è¯¯å·®åˆ†å¸ƒ', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ç»å¯¹è¯¯å·®ç›´æ–¹å›¾\n",
    "axes[1].hist(absolute_errors, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].axvline(np.mean(absolute_errors), color='r', linestyle='--', \n",
    "                linewidth=2, label=f'å¹³å‡å€¼: {np.mean(absolute_errors):.4f}')\n",
    "axes[1].set_xlabel('ç»å¯¹è¯¯å·®', fontsize=12)\n",
    "axes[1].set_ylabel('é¢‘æ•°', fontsize=12)\n",
    "axes[1].set_title('ç»å¯¹è¯¯å·®åˆ†å¸ƒ', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# è¯¯å·®æ•£ç‚¹å›¾\n",
    "axes[2].scatter(absolute_errors, relative_errors, alpha=0.5, s=20)\n",
    "axes[2].set_xlabel('ç»å¯¹è¯¯å·®', fontsize=12)\n",
    "axes[2].set_ylabel('ç›¸å¯¹è¯¯å·®', fontsize=12)\n",
    "axes[2].set_title('ç»å¯¹è¯¯å·® vs ç›¸å¯¹è¯¯å·®', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"\\n=== è¯¯å·®ç»Ÿè®¡ ===\")\n",
    "print(f\"ç›¸å¯¹è¯¯å·® - å¹³å‡: {np.mean(relative_errors):.6f}, æ ‡å‡†å·®: {np.std(relative_errors):.6f}\")\n",
    "print(f\"ç›¸å¯¹è¯¯å·® - æœ€å°: {np.min(relative_errors):.6f}, æœ€å¤§: {np.max(relative_errors):.6f}\")\n",
    "print(f\"ç»å¯¹è¯¯å·® - å¹³å‡: {np.mean(absolute_errors):.6f}, æ ‡å‡†å·®: {np.std(absolute_errors):.6f}\")\n",
    "print(f\"ç»å¯¹è¯¯å·® - æœ€å°: {np.min(absolute_errors):.6f}, æœ€å¤§: {np.max(absolute_errors):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e96471",
   "metadata": {},
   "source": [
    "## 6. å®æˆ˜æ¡ˆä¾‹ï¼šçƒ­ä¼ å¯¼æ–¹ç¨‹\n",
    "\n",
    "### 6.1 æ—¶é—´æ¼”åŒ–å¯è§†åŒ–\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹Transformerå¦‚ä½•æ•æ‰çƒ­ä¼ å¯¼çš„æ—¶é—´æ¼”åŒ–è¿‡ç¨‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27669a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_evolution(initial_condition, x_grid, nt=50, alpha=0.01):\n",
    "    \"\"\"ç”Ÿæˆæ—¶é—´æ¼”åŒ–åºåˆ—\"\"\"\n",
    "    nx = len(x_grid)\n",
    "    dx = x_grid[1] - x_grid[0]\n",
    "    dt = 1.0 / (nt - 1)\n",
    "    r = alpha * dt / dx**2\n",
    "    \n",
    "    u = np.zeros((nt, nx))\n",
    "    u[0] = initial_condition\n",
    "    u[:, 0] = 0\n",
    "    u[:, -1] = 0\n",
    "    \n",
    "    for n in range(0, nt-1):\n",
    "        for i in range(1, nx-1):\n",
    "            u[n+1, i] = u[n, i] + r * (u[n, i+1] - 2*u[n, i] + u[n, i-1])\n",
    "    \n",
    "    return u\n",
    "\n",
    "# é€‰æ‹©ä¸€ä¸ªåˆå§‹æ¡ä»¶\n",
    "test_idx = 0\n",
    "initial = X_test[test_idx]\n",
    "true_evolution = generate_time_evolution(initial, x_grid)\n",
    "\n",
    "# ä½¿ç”¨æ¨¡å‹è¿›è¡Œå¤šæ­¥é¢„æµ‹ï¼ˆè¿™é‡Œæˆ‘ä»¬ç®€åŒ–ä¸ºç›´æ¥é¢„æµ‹æœ€ç»ˆçŠ¶æ€ï¼‰\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    input_data = torch.FloatTensor(initial).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "    coords_data = torch.FloatTensor(x_grid).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "    final_pred = model(input_data, coords_data).cpu().numpy()[0, :, 0]\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# çœŸå®çš„æ—¶é—´æ¼”åŒ–\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "time_steps_to_show = [0, 10, 20, 30, 40, 49]\n",
    "for t_idx in time_steps_to_show:\n",
    "    ax1.plot(x_grid, true_evolution[t_idx], linewidth=2, \n",
    "             label=f't = {t_idx/(len(true_evolution)-1):.2f}')\n",
    "ax1.set_xlabel('x', fontsize=12)\n",
    "ax1.set_ylabel('u(x, t)', fontsize=12)\n",
    "ax1.set_title('çœŸå®çš„æ—¶é—´æ¼”åŒ–', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# çƒ­åŠ›å›¾\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "im = ax2.imshow(true_evolution.T, aspect='auto', origin='lower', \n",
    "                extent=[0, 1, 0, 1], cmap='hot')\n",
    "ax2.set_xlabel('æ—¶é—´ t', fontsize=12)\n",
    "ax2.set_ylabel('ç©ºé—´ x', fontsize=12)\n",
    "ax2.set_title('çƒ­ä¼ å¯¼æ—¶ç©ºæ¼”åŒ–', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax2, label='u(x, t)')\n",
    "\n",
    "# åˆå§‹ vs æœ€ç»ˆçŠ¶æ€å¯¹æ¯”\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax3.plot(x_grid, initial, 'b-', linewidth=2, label='åˆå§‹æ¡ä»¶')\n",
    "ax3.plot(x_grid, true_evolution[-1], 'g-', linewidth=2, label='çœŸå®æœ€ç»ˆçŠ¶æ€')\n",
    "ax3.plot(x_grid, final_pred, 'r--', linewidth=2, label='é¢„æµ‹æœ€ç»ˆçŠ¶æ€')\n",
    "ax3.set_xlabel('x', fontsize=12)\n",
    "ax3.set_ylabel('u', fontsize=12)\n",
    "ax3.set_title('åˆå§‹ vs æœ€ç»ˆçŠ¶æ€', fontsize=14, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# è¯¯å·®åˆ†å¸ƒ\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "error = np.abs(final_pred - true_evolution[-1])\n",
    "ax4.plot(x_grid, error, 'r-', linewidth=2)\n",
    "ax4.fill_between(x_grid, 0, error, alpha=0.3, color='red')\n",
    "ax4.set_xlabel('x', fontsize=12)\n",
    "ax4.set_ylabel('ç»å¯¹è¯¯å·®', fontsize=12)\n",
    "ax4.set_title(f'é¢„æµ‹è¯¯å·®åˆ†å¸ƒ (æœ€å¤§è¯¯å·®: {np.max(error):.4f})', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097135e3",
   "metadata": {},
   "source": [
    "## 7. æ€»ç»“ä¸å±•æœ›\n",
    "\n",
    "### 7.1 æœ¬æ•™ç¨‹å­¦åˆ°çš„å†…å®¹\n",
    "\n",
    "âœ… **åŸºç¡€æ¦‚å¿µ**ï¼š\n",
    "- Transformerçš„æ ¸å¿ƒåŸç†ï¼šè‡ªæ³¨æ„åŠ›æœºåˆ¶\n",
    "- ä½ç½®ç¼–ç åœ¨PDEä¸­çš„åº”ç”¨\n",
    "- åºåˆ—å»ºæ¨¡æ€æƒ³\n",
    "\n",
    "âœ… **å®è·µæŠ€èƒ½**ï¼š\n",
    "- æ•°æ®å‡†å¤‡ä¸é¢„å¤„ç†\n",
    "- æ„å»ºé€‚ç”¨äºPDEçš„Transformeræ¨¡å‹\n",
    "- è®­ç»ƒä¸è¯„ä¼°æµç¨‹\n",
    "- ç»“æœå¯è§†åŒ–ä¸è¯¯å·®åˆ†æ\n",
    "\n",
    "âœ… **åº”ç”¨æ¡ˆä¾‹**ï¼š\n",
    "- 1Dçƒ­ä¼ å¯¼æ–¹ç¨‹æ±‚è§£\n",
    "- æ—¶é—´æ¼”åŒ–é¢„æµ‹\n",
    "\n",
    "### 7.2 è¿›é˜¶æ–¹å‘\n",
    "\n",
    "ğŸš€ **æ¨¡å‹æ”¹è¿›**ï¼š\n",
    "- å°è¯•Vision Transformerå¤„ç†2D/3Dé—®é¢˜\n",
    "- å¼•å…¥ç‰©ç†ä¿¡æ¯çº¦æŸï¼ˆPhysics-Informed Transformerï¼‰\n",
    "- å¤šå°ºåº¦æ³¨æ„åŠ›æœºåˆ¶\n",
    "- å›¾Transformerå¤„ç†ä¸è§„åˆ™ç½‘æ ¼\n",
    "\n",
    "ğŸš€ **åº”ç”¨æ‰©å±•**ï¼š\n",
    "- Navier-Stokesæ–¹ç¨‹ï¼ˆæµä½“åŠ›å­¦ï¼‰\n",
    "- Maxwellæ–¹ç¨‹ï¼ˆç”µç£å­¦ï¼‰\n",
    "- SchrÃ¶dingeræ–¹ç¨‹ï¼ˆé‡å­åŠ›å­¦ï¼‰\n",
    "- å¤šç‰©ç†åœºè€¦åˆé—®é¢˜\n",
    "\n",
    "ğŸš€ **æ€§èƒ½ä¼˜åŒ–**ï¼š\n",
    "- æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "- æ¨¡å‹å‰ªæä¸é‡åŒ–\n",
    "- åˆ†å¸ƒå¼è®­ç»ƒ\n",
    "- è¿ç§»å­¦ä¹ \n",
    "\n",
    "### 7.3 ç›¸å…³èµ„æº\n",
    "\n",
    "ğŸ“š **è®ºæ–‡**ï¼š\n",
    "- \"Choose a Transformer: Fourier or Galerkin\" (NeurIPS 2021)\n",
    "- \"Transformer for Partial Differential Equations' Operator Learning\" (2022)\n",
    "- \"Physics-Informed Neural Networks: A Deep Learning Framework\" (2019)\n",
    "\n",
    "ğŸ’» **ä»£ç åº“**ï¼š\n",
    "- æœ¬é¡¹ç›®ï¼š`AI4CFD/Transformer/`\n",
    "- PyTorchå®˜æ–¹æ–‡æ¡£ï¼šhttps://pytorch.org/docs/stable/nn.html#transformer\n",
    "- Hugging Face Transformersï¼šhttps://huggingface.co/transformers/\n",
    "\n",
    "---\n",
    "\n",
    "**æ„Ÿè°¢ä½¿ç”¨æœ¬æ•™ç¨‹ï¼å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿æIssueæˆ–PRã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d3ac2",
   "metadata": {},
   "source": [
    "## é™„å½•ï¼šæ¨¡å‹ä¿å­˜ä¸åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ec086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜å®Œæ•´æ¨¡å‹\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'best_test_loss': best_test_loss,\n",
    "}, 'transformer_checkpoint.pth')\n",
    "\n",
    "print(\"æ¨¡å‹å·²ä¿å­˜åˆ° transformer_checkpoint.pth\")\n",
    "\n",
    "# åŠ è½½æ¨¡å‹ç¤ºä¾‹\n",
    "# checkpoint = torch.load('transformer_checkpoint.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# print(f\"æ¨¡å‹å·²åŠ è½½ï¼Œæœ€ä½³æµ‹è¯•æŸå¤±: {checkpoint['best_test_loss']:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
