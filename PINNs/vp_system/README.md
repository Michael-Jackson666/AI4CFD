# Vlasov-Poisson PINN æ±‚è§£å™¨

åŸºäºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ(PINNs)çš„ 1D Vlasov-Poisson ç³»ç»Ÿæ±‚è§£å™¨ï¼Œæ”¯æŒå¤šç§ç¥ç»ç½‘ç»œæ¶æ„ï¼ˆMLPã€Transformer ç­‰ï¼‰ï¼Œå¹¶å…·æœ‰å®Œæ•´çš„é…ç½®è¿½è¸ªåŠŸèƒ½ã€‚

## âœ¨ ä¸»è¦ç‰¹æ€§

- ğŸ¯ **å¤šæ¶æ„æ”¯æŒ**: MLPã€Transformerã€Lightweight Transformerã€Hybrid Transformer
- ğŸ’¾ **é…ç½®è‡ªåŠ¨ä¿å­˜**: æ¯æ¬¡è®­ç»ƒè‡ªåŠ¨ä¿å­˜å®Œæ•´é…ç½®ï¼ˆJSON + TXTï¼‰
- ğŸ” **é…ç½®å¯¹æ¯”å·¥å…·**: è½»æ¾å¯¹æ¯”ä¸åŒå®éªŒçš„å‚æ•°è®¾ç½®
- ğŸ“Š **å½’ä¸€åŒ–è¾“å…¥**: æ”¹è¿›çš„è®­ç»ƒç¨³å®šæ€§
- ğŸ“ˆ **å¯è§†åŒ–**: è‡ªåŠ¨ç”Ÿæˆç›¸ç©ºé—´æ¼”åŒ–å›¾å’ŒæŸå¤±æ›²çº¿
- ğŸš€ **ç®€å•æ˜“ç”¨**: ä¸€è¡Œä»£ç åˆ‡æ¢æ¨¡å‹æ¶æ„

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install torch numpy matplotlib
```

### 2. è¿è¡Œè®­ç»ƒ

```bash
cd /Users/jack/Desktop/ML/AI4CFD/PINNs/vp_system
python main.py
```

### 3. åˆ‡æ¢æ¨¡å‹æ¶æ„

åœ¨ `main.py` ä¸­ä¿®æ”¹ä¸€è¡Œä»£ç ï¼š

```python
'model_type': 'mlp',  # æ”¹æˆ 'transformer', 'lightweight_transformer', æˆ– 'hybrid_transformer'
```

å°±è¿™ä¹ˆç®€å•ï¼ğŸ‰

---

## ğŸ“¦ å¯ç”¨çš„æ¨¡å‹æ¶æ„

### 1. MLP (é»˜è®¤) - å¿«é€Ÿç¨³å®š

```python
configuration = {
    'model_type': 'mlp',
    'nn_layers': 8,      # éšè—å±‚æ•°
    'nn_neurons': 128,   # æ¯å±‚ç¥ç»å…ƒæ•°
}
```

**ç‰¹ç‚¹**: 
- âœ… è®­ç»ƒå¿«ï¼ˆ~20åˆ†é’Ÿ/1000 epochsï¼‰
- âœ… å‚æ•°å°‘ï¼ˆ~133Kï¼‰
- âœ… ç¨³å®šå¯é 

**é€‚ç”¨**: å¿«é€ŸåŸå‹ã€æ ‡å‡†é—®é¢˜

---

### 2. Lightweight Transformer - å¹³è¡¡é€‰æ‹©

```python
configuration = {
    'model_type': 'lightweight_transformer',
    'd_model': 128,
    'nhead': 4,
    'num_transformer_layers': 3,
}
```

**ç‰¹ç‚¹**:
- âœ… Transformer ä¼˜åŠ¿
- âœ… è®­ç»ƒè¾ƒå¿«ï¼ˆ~30åˆ†é’Ÿï¼‰
- âœ… å‚æ•°é€‚ä¸­ï¼ˆ~600Kï¼‰

**é€‚ç”¨**: å®éªŒæ¢ç´¢ã€ä¸­ç­‰å¤æ‚åº¦

---

### 3. Standard Transformer - é«˜æ€§èƒ½

```python
configuration = {
    'model_type': 'transformer',
    'd_model': 256,
    'nhead': 8,
    'num_transformer_layers': 6,
}
```

**ç‰¹ç‚¹**:
- âœ… å¼ºå¤§è¡¨è¾¾èƒ½åŠ›
- âœ… æ•æ‰å…¨å±€ç‰¹å¾
- âš ï¸ è®­ç»ƒæ…¢ï¼ˆ~45åˆ†é’Ÿï¼‰
- âš ï¸ å‚æ•°å¤šï¼ˆ~2.5Mï¼‰

**é€‚ç”¨**: å¤æ‚é—®é¢˜ã€é«˜ç²¾åº¦éœ€æ±‚

---

### 4. Hybrid Transformer - æœ€å¼ºç»„åˆ

```python
configuration = {
    'model_type': 'hybrid_transformer',
    'd_model': 256,
    'nhead': 8,
    'num_transformer_layers': 4,
    'num_mlp_layers': 4,
}
```

**ç‰¹ç‚¹**:
- âœ… å…¨å±€+å±€éƒ¨ç‰¹å¾
- âœ… æœ€é«˜ç²¾åº¦
- âš ï¸ æœ€æ…¢ï¼ˆ~60åˆ†é’Ÿ+ï¼‰
- âš ï¸ å‚æ•°æœ€å¤šï¼ˆ~3M+ï¼‰

**é€‚ç”¨**: æœ€å¤æ‚é—®é¢˜ã€è¿½æ±‚æè‡´ç²¾åº¦

---

## ğŸ“Š æ¨¡å‹å¯¹æ¯”è¡¨

| æ¨¡å‹ | å‚æ•°é‡ | è®­ç»ƒæ—¶é—´ | GPUå†…å­˜ | æ¨èåœºæ™¯ |
|-----|-------|---------|---------|----------|
| **MLP** | 133K | ~20åˆ†é’Ÿ | ä½ | æ—¥å¸¸ä½¿ç”¨ã€å¿«é€Ÿæµ‹è¯• |
| **Lightweight Transformer** | 600K | ~30åˆ†é’Ÿ | ä¸­ | å®éªŒæ¢ç´¢ |
| **Standard Transformer** | 2.5M | ~45åˆ†é’Ÿ | é«˜ | å¤æ‚é—®é¢˜ |
| **Hybrid Transformer** | 3M+ | ~60åˆ†é’Ÿ+ | å¾ˆé«˜ | æœ€é«˜ç²¾åº¦ |

*åŸºäº 1000 epochs çš„å¤§è‡´æ—¶é—´*

---

## ğŸ”§ é…ç½®ä¿å­˜ä¸è¿½è¸ª

### è‡ªåŠ¨ä¿å­˜é…ç½®

æ¯æ¬¡è®­ç»ƒä¼šè‡ªåŠ¨ç”Ÿæˆï¼š

```
plot_dir/
â”œâ”€â”€ training_config.json    # JSON æ ¼å¼ï¼ˆç¨‹åºå¯è¯»ï¼‰
â”œâ”€â”€ training_config.txt     # æ–‡æœ¬æ ¼å¼ï¼ˆäººç±»å¯è¯»ï¼‰
â”œâ”€â”€ training_log.txt        # è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ loss_history.png        # æŸå¤±æ›²çº¿
â””â”€â”€ results_epoch_*.png     # ç›¸ç©ºé—´æ¼”åŒ–å›¾
```

### æŸ¥çœ‹é…ç½®

```bash
# æŸ¥çœ‹æ–‡æœ¬é…ç½®
cat 2025/10/13/2/training_config.txt

# æŸ¥çœ‹ JSON é…ç½®
cat 2025/10/13/2/training_config.json
```

### å¯¹æ¯”ä¸åŒå®éªŒ

```bash
# äº¤äº’å¼å¯¹æ¯”å·¥å…·
python compare_configs.py

# åˆ—å‡ºæ‰€æœ‰é…ç½®
python compare_configs.py list

# å¯¹æ¯”ä¸¤ä¸ªé…ç½®
python compare_configs.py compare config1.json config2.json
```

**ç¤ºä¾‹è¾“å‡º**:

```
[Model]
  model_type          | mlp              | transformer          
  nn_layers           | 8                | N/A                  
  d_model             | N/A              | 256                  

[Training]
  epochs              | 2000             | 5000                 
  learning_rate       | 0.0001           | 5e-05                
```

---

## ğŸ“– å®Œæ•´é…ç½®ç¤ºä¾‹

### ç¤ºä¾‹ 1: å¿«é€Ÿæµ‹è¯•ï¼ˆ5-10åˆ†é’Ÿï¼‰

```python
configuration = {
    # æ¨¡å‹
    'model_type': 'mlp',
    'nn_layers': 6,
    'nn_neurons': 64,
    
    # è®­ç»ƒ
    'epochs': 500,
    'learning_rate': 1e-4,
    
    # è¾“å‡º
    'plot_dir': 'quick_test',
    'log_frequency': 50,
    'plot_frequency': 100,
}
```

### ç¤ºä¾‹ 2: æ ‡å‡†è®­ç»ƒï¼ˆ30åˆ†é’Ÿï¼‰

```python
configuration = {
    # æ¨¡å‹
    'model_type': 'mlp',
    'nn_layers': 8,
    'nn_neurons': 128,
    
    # è®­ç»ƒ
    'epochs': 2000,
    'learning_rate': 1e-4,
    'n_pde': 70000,
    'n_ic': 1100,
    'n_bc': 1100,
    
    # æŸå¤±æƒé‡
    'weight_pde': 1.0,
    'weight_ic': 5.0,
    'weight_bc': 10.0,
    
    # è¾“å‡º
    'plot_dir': 'experiments/mlp_standard',
}
```

### ç¤ºä¾‹ 3: Transformer é«˜ç²¾åº¦ï¼ˆ2-4å°æ—¶ï¼‰

```python
configuration = {
    # æ¨¡å‹
    'model_type': 'transformer',
    'd_model': 256,
    'nhead': 8,
    'num_transformer_layers': 6,
    'dim_feedforward': 1024,
    'dropout': 0.1,
    
    # è®­ç»ƒ
    'epochs': 5000,
    'learning_rate': 5e-5,  # æ›´å°çš„å­¦ä¹ ç‡
    'n_pde': 100000,        # æ›´å¤šé‡‡æ ·ç‚¹
    
    # è¾“å‡º
    'plot_dir': 'experiments/transformer_high_precision',
}
```

---

## ğŸ“ æ–‡ä»¶ç»“æ„

```
vp_system/
â”œâ”€â”€ main.py                     # ä¸»è®­ç»ƒè„šæœ¬ â­
â”œâ”€â”€ vp_pinn.py                  # PINN æ±‚è§£å™¨æ ¸å¿ƒ
â”œâ”€â”€ mlp.py                      # MLP æ¨¡å‹å®šä¹‰
â”œâ”€â”€ transformer.py              # Transformer æ¨¡å‹å®šä¹‰
â”œâ”€â”€ visualization.py            # å¯è§†åŒ–å‡½æ•°
â”œâ”€â”€ compare_configs.py          # é…ç½®å¯¹æ¯”å·¥å…·
â”œâ”€â”€ compare_models.py           # æ¨¡å‹å¯¹æ¯”å®éªŒè„šæœ¬
â””â”€â”€ README.md                   # æœ¬æ–‡æ¡£
```

---

## ğŸ¯ ä½¿ç”¨å·¥ä½œæµ

### 1. å¿«é€Ÿæµ‹è¯•

```bash
# ä½¿ç”¨é»˜è®¤ MLPï¼Œ500 epochs
python main.py
```

ä¿®æ”¹ `main.py` ä¸­çš„ `epochs` ä¸º 500 è¿›è¡Œå¿«é€Ÿæµ‹è¯•ã€‚

### 2. æ ‡å‡†è®­ç»ƒ

```python
# main.py ä¸­ä¿æŒé»˜è®¤é…ç½®
'model_type': 'mlp',
'epochs': 2000,
```

```bash
python main.py
```

### 3. å°è¯• Transformer

```python
# main.py ä¸­ä¿®æ”¹
'model_type': 'lightweight_transformer',
'epochs': 1500,
```

```bash
python main.py
```

### 4. å¯¹æ¯”å®éªŒ

```bash
# è¿è¡Œå¯¹æ¯”è„šæœ¬
python compare_models.py

# é€‰æ‹©ï¼š
# 1. å¯¹æ¯”ä¸åŒæ¶æ„
# 2. å¯¹æ¯”ä¸åŒæ¿€æ´»å‡½æ•°
# 3. å¯¹æ¯”ä¸åŒç½‘ç»œè§„æ¨¡
```

### 5. åˆ†æç»“æœ

```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
cat experiments/*/training_log.txt

# å¯¹æ¯”é…ç½®
python compare_configs.py

# æŸ¥çœ‹å¯è§†åŒ–ç»“æœ
# æ‰“å¼€ plot_dir ä¸­çš„ PNG å›¾ç‰‡
```

---

## ğŸ“š æ–¹ç¨‹ç»„è¯´æ˜

### 1D Vlasov-Poisson ç³»ç»Ÿ

**Vlasov æ–¹ç¨‹** (æè¿°ç²’å­åˆ†å¸ƒæ¼”åŒ–):
$$\frac{\partial f}{\partial t} + v \frac{\partial f}{\partial x} - E(x,t) \frac{\partial f}{\partial v} = 0$$

**Poisson æ–¹ç¨‹** (ç”µåœºä¸å¯†åº¦å…³ç³»):
$$\frac{\partial E}{\partial x} = n_e(x,t) - 1$$

å…¶ä¸­:
- $f(t,x,v)$: ç²’å­åˆ†å¸ƒå‡½æ•°
- $E(x,t)$: ç”µåœº
- $n_e(x,t) = \int f(t,x,v) dv$: ç”µå­å¯†åº¦

### åˆå§‹æ¡ä»¶: åŒæµä¸ç¨³å®šæ€§

$$f(0,x,v) = \frac{1}{2\sigma\sqrt{2\pi}} \left[e^{-(v-v_b)^2/(2\sigma^2)} + e^{-(v+v_b)^2/(2\sigma^2)}\right] \times [1 + A\cos(kx)]$$

å‚æ•°:
- $v_b = 1.0$: æŸæµé€Ÿåº¦
- $\sigma = 0.5$: çƒ­é€Ÿåº¦
- $A = 0.1$: æ‰°åŠ¨å¹…åº¦
- $k = 2\pi/L_x$: æ³¢æ•°

---

## ğŸ” é…ç½®å‚æ•°è¯´æ˜

### åŸŸå‚æ•°

```python
't_max': 62.5,      # æœ€å¤§æ—¶é—´
'x_max': 10.0,      # ç©ºé—´åŸŸé•¿åº¦  
'v_max': 5.0,       # æœ€å¤§é€Ÿåº¦
```

### ç‰©ç†å‚æ•°

```python
'beam_v': 1.0,          # æŸæµé€Ÿåº¦
'thermal_v': 0.5,       # çƒ­é€Ÿåº¦
'perturb_amp': 0.1,     # æ‰°åŠ¨å¹…åº¦
```

### è®­ç»ƒå‚æ•°

```python
'epochs': 2000,         # è®­ç»ƒè½®æ•°
'learning_rate': 1e-4,  # å­¦ä¹ ç‡
'n_pde': 70000,         # PDEé‡‡æ ·ç‚¹æ•°
'n_ic': 1100,           # åˆå§‹æ¡ä»¶ç‚¹æ•°
'n_bc': 1100,           # è¾¹ç•Œæ¡ä»¶ç‚¹æ•°
```

### æŸå¤±æƒé‡

```python
'weight_pde': 1.0,      # PDEæŸå¤±æƒé‡
'weight_ic': 5.0,       # åˆå§‹æ¡ä»¶æƒé‡
'weight_bc': 10.0,      # è¾¹ç•Œæ¡ä»¶æƒé‡
```

---

## ğŸ› ï¸ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒä¸ç¨³å®šæ€ä¹ˆåŠï¼Ÿ

**æ–¹æ¡ˆ**:
1. é™ä½å­¦ä¹ ç‡: `'learning_rate': 5e-5`
2. å¢åŠ  dropout (Transformer): `'dropout': 0.2`
3. å‡å°‘æ¨¡å‹è§„æ¨¡

### Q2: å¦‚ä½•æé«˜ç²¾åº¦ï¼Ÿ

**æ–¹æ¡ˆ**:
1. å¢åŠ è®­ç»ƒè½®æ•°: `'epochs': 5000`
2. ä½¿ç”¨æ›´å¤§æ¨¡å‹: `'transformer'` æˆ– `'hybrid_transformer'`
3. å¢åŠ é‡‡æ ·ç‚¹: `'n_pde': 100000`
4. è°ƒæ•´æŸå¤±æƒé‡

### Q3: è®­ç»ƒå¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**æ–¹æ¡ˆ**:
1. ä½¿ç”¨ MLP: `'model_type': 'mlp'`
2. å‡å°‘é‡‡æ ·ç‚¹: `'n_pde': 50000`
3. ä½¿ç”¨ GPU åŠ é€Ÿ
4. é™ä½å¯è§†åŒ–é¢‘ç‡: `'plot_frequency': 1000`

### Q4: å¦‚ä½•å¯¹æ¯”ä¸åŒæ¨¡å‹ï¼Ÿ

**æ–¹æ¡ˆ**:
```bash
python compare_models.py
```
é€‰æ‹©"å¯¹æ¯”ä¸åŒæ¶æ„"ï¼Œè‡ªåŠ¨è¿è¡Œå¹¶å¯¹æ¯”ç»“æœã€‚

---

## ğŸ“ˆ æ€§èƒ½è°ƒä¼˜å»ºè®®

### è¿‡æ‹Ÿåˆ
- å¢åŠ  dropout
- å‡å°‘æ¨¡å‹å¤æ‚åº¦
- å¢åŠ æ­£åˆ™åŒ–æƒé‡

### æ¬ æ‹Ÿåˆ
- å¢åŠ æ¨¡å‹å®¹é‡
- å¢åŠ è®­ç»ƒè½®æ•°
- é™ä½å­¦ä¹ ç‡ï¼Œè®­ç»ƒæ›´ä¹…

### ä¸ç¨³å®š
- é™ä½å­¦ä¹ ç‡
- ä½¿ç”¨æ¢¯åº¦è£å‰ªï¼ˆå·²å†…ç½®ï¼‰
- æ£€æŸ¥åˆå§‹æ¡ä»¶

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶è¯´æ˜

æ¯æ¬¡è®­ç»ƒç”Ÿæˆçš„æ–‡ä»¶ï¼š

```
plot_dir/
â”œâ”€â”€ training_config.json        # é…ç½®ï¼ˆJSONæ ¼å¼ï¼‰
â”œâ”€â”€ training_config.txt         # é…ç½®ï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰
â”œâ”€â”€ training_log.txt           # CSVæ ¼å¼è®­ç»ƒæ—¥å¿—
â”‚   æ ¼å¼: Epoch,Total_Loss,PDE_Loss,IC_Loss,BC_Loss,Time_s
â”œâ”€â”€ loss_history.png           # æŸå¤±æ›²çº¿å›¾
â””â”€â”€ results_epoch_XXXX.png     # å‘¨æœŸæ€§ç»“æœå›¾
    â”œâ”€â”€ ç›¸ç©ºé—´æ¼”åŒ–ï¼ˆ3ä¸ªæ—¶é—´æ­¥ï¼‰
    â”œâ”€â”€ åˆå§‹æ¡ä»¶å¯¹æ¯”
    â”œâ”€â”€ å¯†åº¦åˆ†å¸ƒ
    â””â”€â”€ ç”µåœºåˆ†å¸ƒ
```

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: åŸºç¡€ä½¿ç”¨

```python
# main.py ä¸­ä½¿ç”¨é»˜è®¤é…ç½®
python main.py
```

### ç¤ºä¾‹ 2: åˆ‡æ¢åˆ° Transformer

```python
# ä¿®æ”¹ main.py
configuration['model_type'] = 'transformer'
configuration['d_model'] = 256
configuration['nhead'] = 8
configuration['num_transformer_layers'] = 6
```

### ç¤ºä¾‹ 3: æ‰¹é‡å®éªŒ

```bash
# ä½¿ç”¨å¯¹æ¯”è„šæœ¬
python compare_models.py

# é€‰æ‹©é€‰é¡¹ 1: å¯¹æ¯”ä¸åŒæ¶æ„
# ä¼šè‡ªåŠ¨è¿è¡Œ MLPã€Lightweight Transformerã€Standard Transformer
```

### ç¤ºä¾‹ 4: æŸ¥çœ‹å’Œå¯¹æ¯”ç»“æœ

```bash
# åˆ—å‡ºæ‰€æœ‰å®éªŒ
python compare_configs.py list

# å¯¹æ¯”ä¸¤ä¸ªå®éªŒ
python compare_configs.py
# é€‰æ‹© 2: å¯¹æ¯”ä¸¤ä¸ªé…ç½®
```

---

## ğŸŒŸ å¿«é€Ÿå‚è€ƒ

| ä»»åŠ¡ | å‘½ä»¤/æ“ä½œ |
|-----|----------|
| è¿è¡Œè®­ç»ƒ | `python main.py` |
| åˆ‡æ¢æ¨¡å‹ | ä¿®æ”¹ `'model_type'` |
| å¯¹æ¯”æ¨¡å‹ | `python compare_models.py` |
| æŸ¥çœ‹é…ç½® | `python compare_configs.py` |
| å¿«é€Ÿæµ‹è¯• | è®¾ç½® `'epochs': 500` |

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **é¦–æ¬¡ä½¿ç”¨**: å…ˆç”¨ MLP + 500 epochs å¿«é€Ÿæµ‹è¯•
2. **å®éªŒå‘½å**: ä½¿ç”¨æœ‰æ„ä¹‰çš„ `plot_dir` åç§°
3. **è®°å½•ç¬”è®°**: åœ¨è¾“å‡ºç›®å½•æ·»åŠ  `notes.txt`
4. **å®šæœŸå¯¹æ¯”**: ç”¨ `compare_configs.py` è¿½è¸ªæ”¹è¿›
5. **ä¿å­˜å¥½ç»“æœ**: å¤‡ä»½æ•ˆæœå¥½çš„é…ç½®å’Œæ¨¡å‹

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [æ¨¡å‹æ¶æ„è¯¦ç»†è¯´æ˜](MODEL_SELECTION_GUIDE.md) - å·²åˆ é™¤ï¼Œå†…å®¹å·²æ•´åˆ
- [é…ç½®è¿½è¸ªæŒ‡å—](CONFIG_TRACKING_GUIDE.md) - å·²åˆ é™¤ï¼Œå†…å®¹å·²æ•´åˆ

---

## ğŸ“§ æ”¯æŒ

é‡åˆ°é—®é¢˜ï¼Ÿ
1. æŸ¥çœ‹æœ¬ README
2. è¿è¡Œ `python compare_configs.py` æ£€æŸ¥é…ç½®
3. æŸ¥çœ‹è®­ç»ƒæ—¥å¿— `training_log.txt`

---

**å¼€å§‹ä½ çš„ Vlasov-Poisson PINN è®­ç»ƒä¹‹æ—…ï¼** ğŸš€

```bash
python main.py
```
