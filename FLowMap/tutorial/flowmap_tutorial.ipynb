{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d1d706",
   "metadata": {},
   "source": [
    "# Flow Map Learning (æµæ˜ å°„å­¦ä¹ ) æ•™ç¨‹\n",
    "\n",
    "## ğŸ“š ç®€ä»‹\n",
    "\n",
    "**Flow Map Learning** æ˜¯ç”±ä¿®ä¸œæ»¨æ•™æˆå›¢é˜Ÿæå‡ºçš„ä¸€ç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºå­¦ä¹ æ—¶é—´ç§¯åˆ†ç®—å­ï¼ˆæ—¶é—´æµæ˜ å°„ï¼‰ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚PINNsï¼‰ç›´æ¥å­¦ä¹ è§£å‡½æ•°ä¸åŒï¼ŒFlow Map Learning å­¦ä¹ ç³»ç»Ÿä»å½“å‰çŠ¶æ€åˆ°æœªæ¥çŠ¶æ€çš„æ˜ å°„ã€‚\n",
    "\n",
    "### æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "å¯¹äºåŠ¨åŠ›ç³»ç»Ÿï¼š\n",
    "$$\\frac{d\\mathbf{x}}{dt} = \\mathbf{f}(\\mathbf{x}, t)$$\n",
    "\n",
    "**æµæ˜ å°„** $\\Phi_{\\Delta t}$ å°†çŠ¶æ€ä»æ—¶åˆ» $t$ æ˜ å°„åˆ° $t + \\Delta t$ï¼š\n",
    "$$\\mathbf{x}(t + \\Delta t) = \\Phi_{\\Delta t}(\\mathbf{x}(t))$$\n",
    "\n",
    "**Flow Map Learning** ä½¿ç”¨ç¥ç»ç½‘ç»œ $\\mathcal{N}_\\theta$ é€¼è¿‘è¿™ä¸ªæ˜ å°„ï¼š\n",
    "$$\\Phi_{\\Delta t} \\approx \\mathcal{N}_\\theta(\\mathbf{x}, \\Delta t)$$\n",
    "\n",
    "### æ–¹æ³•ä¼˜åŠ¿\n",
    "\n",
    "1. **è‡ªç„¶æ”¯æŒé•¿æœŸé¢„æµ‹**ï¼šé€šè¿‡è¿­ä»£åº”ç”¨æµæ˜ å°„è¿›è¡Œå¤šæ­¥é¢„æµ‹\n",
    "2. **è®­ç»ƒæ•°æ®é«˜æ•ˆ**ï¼šåªéœ€è¦çŸ­æ—¶é—´é—´éš”çš„çŠ¶æ€å¯¹\n",
    "3. **ç‰©ç†ç»“æ„ä¿æŒ**ï¼šå¯è®¾è®¡ä¿è¾›ã€ä¿èƒ½é‡çš„ç½‘ç»œ\n",
    "4. **çµæ´»çš„æ—¶é—´æ­¥é•¿**ï¼šå¯ä»¥å­¦ä¹ ä¸åŒæ—¶é—´æ­¥é•¿çš„æ˜ å°„\n",
    "\n",
    "---\n",
    "\n",
    "### æœ¬æ•™ç¨‹å†…å®¹\n",
    "\n",
    "1. æµæ˜ å°„çš„æ•°å­¦åŸºç¡€\n",
    "2. ç¥ç»ç½‘ç»œæ¶æ„è®¾è®¡\n",
    "3. Lorenz æ··æ²Œç³»ç»Ÿé¢„æµ‹\n",
    "4. 1D çƒ­ä¼ å¯¼æ–¹ç¨‹æ±‚è§£\n",
    "5. è¯¯å·®åˆ†æä¸è®­ç»ƒæŠ€å·§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11188d",
   "metadata": {},
   "source": [
    "## 1. å¯¼å…¥å¿…è¦çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6213b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.integrate import solve_ivp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ç»˜å›¾è®¾ç½®\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"âœ“ åº“å¯¼å…¥æˆåŠŸï¼\")\n",
    "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d03c7e",
   "metadata": {},
   "source": [
    "## 2. æµæ˜ å°„çš„æ•°å­¦åŸºç¡€\n",
    "\n",
    "### 2.1 åŠ¨åŠ›ç³»ç»Ÿä¸æµæ˜ å°„\n",
    "\n",
    "å¯¹äºè‡ªæ²»åŠ¨åŠ›ç³»ç»Ÿï¼š\n",
    "$$\\frac{d\\mathbf{x}}{dt} = \\mathbf{f}(\\mathbf{x})$$\n",
    "\n",
    "**æµæ˜ å°„** $\\Phi_t: \\mathbb{R}^n \\to \\mathbb{R}^n$ å®šä¹‰ä¸ºï¼šç»™å®šåˆå§‹çŠ¶æ€ $\\mathbf{x}_0$ï¼Œ$\\Phi_t(\\mathbf{x}_0)$ æ˜¯ç³»ç»Ÿåœ¨æ—¶é—´ $t$ åçš„çŠ¶æ€ã€‚\n",
    "\n",
    "**ç¾¤æ€§è´¨**ï¼š\n",
    "$$\\Phi_{t_1 + t_2} = \\Phi_{t_2} \\circ \\Phi_{t_1}$$\n",
    "\n",
    "### 2.2 ç¦»æ•£æ—¶é—´æµæ˜ å°„\n",
    "\n",
    "åœ¨å®é™…è®¡ç®—ä¸­ï¼Œæˆ‘ä»¬å…³æ³¨ç¦»æ•£æ—¶é—´æ­¥é•¿ $\\Delta t$ï¼š\n",
    "\n",
    "$$\\mathbf{x}_{n+1} = \\Phi_{\\Delta t}(\\mathbf{x}_n)$$\n",
    "\n",
    "**å¤šæ­¥é¢„æµ‹**é€šè¿‡è¿­ä»£å®ç°ï¼š\n",
    "$$\\mathbf{x}_{N} = \\underbrace{\\Phi_{\\Delta t} \\circ \\Phi_{\\Delta t} \\circ \\cdots \\circ \\Phi_{\\Delta t}}_{N \\text{ æ¬¡}}(\\mathbf{x}_0)$$\n",
    "\n",
    "### 2.3 ç¥ç»ç½‘ç»œé€¼è¿‘\n",
    "\n",
    "ç”¨ç¥ç»ç½‘ç»œ $\\mathcal{N}_\\theta$ é€¼è¿‘æµæ˜ å°„ï¼š\n",
    "$$\\Phi_{\\Delta t}(\\mathbf{x}) \\approx \\mathcal{N}_\\theta(\\mathbf{x}, \\Delta t)$$\n",
    "\n",
    "**æ®‹å·®å½¢å¼**ï¼ˆæ›´å®¹æ˜“å­¦ä¹ ï¼‰ï¼š\n",
    "$$\\mathbf{x}_{n+1} = \\mathbf{x}_n + \\mathcal{N}_\\theta(\\mathbf{x}_n, \\Delta t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed839cf",
   "metadata": {},
   "source": [
    "## 3. æ„å»º Flow Map ç¥ç»ç½‘ç»œ\n",
    "\n",
    "æˆ‘ä»¬å®ç°ä¸€ä¸ªåŸºäº MLP çš„ Flow Map ç½‘ç»œï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š\n",
    "- **æ®‹å·®è¿æ¥**: $\\mathbf{x}_{n+1} = \\mathbf{x}_n + \\mathcal{N}(\\mathbf{x}_n, \\Delta t)$\n",
    "- **æ—¶é—´ç¼–ç **: å¯¹æ—¶é—´æ­¥é•¿è¿›è¡Œéçº¿æ€§ç¼–ç \n",
    "- **å¤šå±‚ç»“æ„**: ä½¿ç”¨å¤šä¸ªéšè—å±‚å¢å¼ºè¡¨è¾¾èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowMapMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Flow Map å¤šå±‚æ„ŸçŸ¥æœº\n",
    "    \n",
    "    å­¦ä¹ ä» (x, Î”t) åˆ° x(t+Î”t) çš„æ˜ å°„\n",
    "    ä½¿ç”¨æ®‹å·®è¿æ¥: x_next = x + NN(x, Î”t)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_dim, hidden_dims=[64, 64, 64], \n",
    "                 activation='tanh', use_residual=True):\n",
    "        super(FlowMapMLP, self).__init__()\n",
    "        \n",
    "        self.state_dim = state_dim\n",
    "        self.use_residual = use_residual\n",
    "        \n",
    "        # æ¿€æ´»å‡½æ•°\n",
    "        activations = {'tanh': nn.Tanh(), 'relu': nn.ReLU(), 'gelu': nn.GELU()}\n",
    "        self.activation = activations.get(activation, nn.Tanh())\n",
    "        \n",
    "        # æ—¶é—´ç¼–ç å™¨\n",
    "        self.time_encoder = nn.Sequential(\n",
    "            nn.Linear(1, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 16)\n",
    "        )\n",
    "        \n",
    "        # ä¸»ç½‘ç»œ\n",
    "        input_dim = state_dim + 16  # çŠ¶æ€ + ç¼–ç åçš„æ—¶é—´\n",
    "        layers = []\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(self.activation)\n",
    "            input_dim = hidden_dim\n",
    "        layers.append(nn.Linear(input_dim, state_dim))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "        # åˆå§‹åŒ–æƒé‡\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x, dt):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        Args:\n",
    "            x: å½“å‰çŠ¶æ€ [batch, state_dim]\n",
    "            dt: æ—¶é—´æ­¥é•¿ (æ ‡é‡æˆ– [batch, 1])\n",
    "        \n",
    "        Returns:\n",
    "            x_next: ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€ [batch, state_dim]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # å¤„ç†æ—¶é—´è¾“å…¥\n",
    "        if isinstance(dt, (float, int)):\n",
    "            dt = torch.ones(batch_size, 1, device=x.device) * dt\n",
    "        elif dt.dim() == 0:\n",
    "            dt = dt.unsqueeze(0).unsqueeze(0).expand(batch_size, 1)\n",
    "        elif dt.dim() == 1:\n",
    "            dt = dt.unsqueeze(-1)\n",
    "        \n",
    "        # æ—¶é—´ç¼–ç \n",
    "        dt_encoded = self.time_encoder(dt)\n",
    "        \n",
    "        # æ‹¼æ¥è¾“å…¥\n",
    "        inputs = torch.cat([x, dt_encoded], dim=-1)\n",
    "        \n",
    "        # ç½‘ç»œè¾“å‡º\n",
    "        dx = self.net(inputs)\n",
    "        \n",
    "        # æ®‹å·®è¿æ¥\n",
    "        if self.use_residual:\n",
    "            return x + dx\n",
    "        return dx\n",
    "    \n",
    "    def multi_step_predict(self, x0, dt, n_steps):\n",
    "        \"\"\"å¤šæ­¥è‡ªå›å½’é¢„æµ‹\"\"\"\n",
    "        if x0.dim() == 1:\n",
    "            x0 = x0.unsqueeze(0)\n",
    "        \n",
    "        trajectory = [x0]\n",
    "        x = x0\n",
    "        \n",
    "        for _ in range(n_steps):\n",
    "            x = self.forward(x, dt)\n",
    "            trajectory.append(x)\n",
    "        \n",
    "        return torch.stack(trajectory, dim=0)\n",
    "\n",
    "# æµ‹è¯•æ¨¡å‹\n",
    "print(\"=\" * 60)\n",
    "print(\"Flow Map ç½‘ç»œæµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model = FlowMapMLP(state_dim=3, hidden_dims=[64, 64, 64])\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"çŠ¶æ€ç»´åº¦: 3\")\n",
    "print(f\"éšè—å±‚: [64, 64, 64]\")\n",
    "print(f\"æ€»å‚æ•°é‡: {n_params}\")\n",
    "print(model)\n",
    "\n",
    "# æµ‹è¯•å‰å‘ä¼ æ’­\n",
    "x_test = torch.randn(10, 3)  # 10ä¸ªæ ·æœ¬ï¼Œ3ç»´çŠ¶æ€\n",
    "dt_test = 0.01\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_next = model(x_test, dt_test)\n",
    "    print(f\"\\nè¾“å…¥å½¢çŠ¶: {x_test.shape}\")\n",
    "    print(f\"è¾“å‡ºå½¢çŠ¶: {x_next.shape}\")\n",
    "    print(\"âœ“ æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74828e2f",
   "metadata": {},
   "source": [
    "## 4. ç¤ºä¾‹1: Lorenz æ··æ²Œç³»ç»Ÿ\n",
    "\n",
    "Lorenz ç³»ç»Ÿæ˜¯ç»å…¸çš„æ··æ²ŒåŠ¨åŠ›ç³»ç»Ÿï¼š\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\frac{dx}{dt} = \\sigma(y - x) \\\\\n",
    "\\frac{dy}{dt} = x(\\rho - z) - y \\\\\n",
    "\\frac{dz}{dt} = xy - \\beta z\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "æ ‡å‡†æ··æ²Œå‚æ•°ï¼š$\\sigma = 10$, $\\rho = 28$, $\\beta = 8/3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29bc1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lorenz ç³»ç»Ÿå®šä¹‰\n",
    "def lorenz_system(state, t, sigma=10.0, rho=28.0, beta=8/3):\n",
    "    \"\"\"Lorenz æ··æ²Œç³»ç»Ÿçš„å³ç«¯é¡¹\"\"\"\n",
    "    x, y, z = state\n",
    "    dxdt = sigma * (y - x)\n",
    "    dydt = x * (rho - z) - y\n",
    "    dzdt = x * y - beta * z\n",
    "    return np.array([dxdt, dydt, dzdt])\n",
    "\n",
    "# ä½¿ç”¨ RK4 ç”ŸæˆçœŸå®è½¨è¿¹\n",
    "def rk4_step(f, y, t, dt, *args):\n",
    "    \"\"\"Runge-Kutta 4é˜¶ç§¯åˆ†å™¨å•æ­¥\"\"\"\n",
    "    k1 = f(y, t, *args)\n",
    "    k2 = f(y + dt/2 * k1, t + dt/2, *args)\n",
    "    k3 = f(y + dt/2 * k2, t + dt/2, *args)\n",
    "    k4 = f(y + dt * k3, t + dt, *args)\n",
    "    return y + dt/6 * (k1 + 2*k2 + 2*k3 + k4)\n",
    "\n",
    "def generate_lorenz_data(n_trajectories=50, n_steps=200, dt=0.02):\n",
    "    \"\"\"ç”Ÿæˆ Lorenz ç³»ç»Ÿè®­ç»ƒæ•°æ®\"\"\"\n",
    "    X_current = []\n",
    "    X_next = []\n",
    "    \n",
    "    for _ in range(n_trajectories):\n",
    "        # éšæœºåˆå§‹æ¡ä»¶ (åœ¨å¸å¼•å­é™„è¿‘)\n",
    "        x0 = np.random.randn(3) * 5 + np.array([0, 0, 25])\n",
    "        \n",
    "        state = x0\n",
    "        for step in range(n_steps):\n",
    "            next_state = rk4_step(lorenz_system, state, step * dt, dt)\n",
    "            X_current.append(state.copy())\n",
    "            X_next.append(next_state.copy())\n",
    "            state = next_state\n",
    "    \n",
    "    return np.array(X_current), np.array(X_next), dt\n",
    "\n",
    "# ç”Ÿæˆè®­ç»ƒæ•°æ®\n",
    "X_current, X_next, dt = generate_lorenz_data(n_trajectories=100, n_steps=300)\n",
    "print(f\"è®­ç»ƒæ•°æ®å½¢çŠ¶: X_current={X_current.shape}, X_next={X_next.shape}\")\n",
    "print(f\"æ—¶é—´æ­¥é•¿ dt = {dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b989452",
   "metadata": {},
   "source": [
    "### 4.1 è®­ç»ƒ Flow Map æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡†å¤‡ PyTorch æ•°æ®\n",
    "X_train = torch.FloatTensor(X_current)\n",
    "Y_train = torch.FloatTensor(X_next)\n",
    "dt_tensor = torch.FloatTensor([dt])\n",
    "\n",
    "# åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "model = FlowMapMLP(state_dim=3, hidden_dims=[128, 128, 128])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# è®­ç»ƒå¾ªç¯\n",
    "n_epochs = 500\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for X_batch, Y_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        Y_pred = model(X_batch, dt_tensor.expand(X_batch.shape[0], 1))\n",
    "        \n",
    "        # è®¡ç®—æŸå¤±\n",
    "        loss = criterion(Y_pred, Y_batch)\n",
    "        \n",
    "        # åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f340a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.semilogy(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Flow Map è®­ç»ƒæŸå¤±æ›²çº¿')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd3bfa",
   "metadata": {},
   "source": [
    "### 4.2 é•¿æœŸé¢„æµ‹ (è‡ªå›å½’å±•å¼€)\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬ä½¿ç”¨ `multi_step_predict` æ–¹æ³•è¿›è¡Œé•¿æœŸè½¨è¿¹é¢„æµ‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bba84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”ŸæˆçœŸå®è½¨è¿¹ç”¨äºå¯¹æ¯”\n",
    "x0_test = np.array([1.0, 1.0, 1.0])\n",
    "n_predict = 1000\n",
    "t_span = np.arange(0, n_predict * dt, dt)\n",
    "\n",
    "# RK4 ç”ŸæˆçœŸå®è½¨è¿¹\n",
    "true_trajectory = [x0_test]\n",
    "state = x0_test.copy()\n",
    "for _ in range(n_predict - 1):\n",
    "    state = rk4_step(lorenz_system, state, 0, dt)\n",
    "    true_trajectory.append(state.copy())\n",
    "true_trajectory = np.array(true_trajectory)\n",
    "\n",
    "# Flow Map é¢„æµ‹\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x0_tensor = torch.FloatTensor(x0_test).unsqueeze(0)\n",
    "    pred_trajectory = model.multi_step_predict(x0_tensor, dt, n_predict)\n",
    "    pred_trajectory = pred_trajectory.squeeze().numpy()\n",
    "\n",
    "print(f\"é¢„æµ‹è½¨è¿¹å½¢çŠ¶: {pred_trajectory.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D å¯è§†åŒ–\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "# çœŸå®è½¨è¿¹\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.plot(true_trajectory[:, 0], true_trajectory[:, 1], true_trajectory[:, 2], \n",
    "         'b-', linewidth=0.5, alpha=0.8)\n",
    "ax1.set_title('çœŸå®è½¨è¿¹ (RK4)')\n",
    "ax1.set_xlabel('X'); ax1.set_ylabel('Y'); ax1.set_zlabel('Z')\n",
    "\n",
    "# é¢„æµ‹è½¨è¿¹\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "ax2.plot(pred_trajectory[:, 0], pred_trajectory[:, 1], pred_trajectory[:, 2], \n",
    "         'r-', linewidth=0.5, alpha=0.8)\n",
    "ax2.set_title('Flow Map é¢„æµ‹')\n",
    "ax2.set_xlabel('X'); ax2.set_ylabel('Y'); ax2.set_zlabel('Z')\n",
    "\n",
    "# å¯¹æ¯”\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "ax3.plot(true_trajectory[:, 0], true_trajectory[:, 1], true_trajectory[:, 2], \n",
    "         'b-', linewidth=0.5, alpha=0.6, label='çœŸå®')\n",
    "ax3.plot(pred_trajectory[:, 0], pred_trajectory[:, 1], pred_trajectory[:, 2], \n",
    "         'r--', linewidth=0.5, alpha=0.6, label='é¢„æµ‹')\n",
    "ax3.set_title('å¯¹æ¯”')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16507496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ—¶é—´åºåˆ—å¯¹æ¯”\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "labels = ['x(t)', 'y(t)', 'z(t)']\n",
    "\n",
    "for i, (ax, label) in enumerate(zip(axes, labels)):\n",
    "    ax.plot(t_span, true_trajectory[:, i], 'b-', linewidth=1, label='çœŸå®', alpha=0.8)\n",
    "    ax.plot(t_span, pred_trajectory[:, i], 'r--', linewidth=1, label='é¢„æµ‹', alpha=0.8)\n",
    "    ax.set_ylabel(label)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('æ—¶é—´ t')\n",
    "fig.suptitle('Lorenz ç³»ç»Ÿæ—¶é—´åºåˆ—å¯¹æ¯”', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148bf0cd",
   "metadata": {},
   "source": [
    "### 4.3 è¯¯å·®åˆ†æ\n",
    "\n",
    "ç”±äº Lorenz ç³»ç»Ÿçš„æ··æ²Œç‰¹æ€§ï¼Œå°çš„è¯¯å·®ä¼šæŒ‡æ•°å¢é•¿ã€‚æˆ‘ä»¬åˆ†æé¢„æµ‹è¯¯å·®éšæ—¶é—´çš„æ¼”åŒ–ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—é¢„æµ‹è¯¯å·®\n",
    "errors = np.linalg.norm(pred_trajectory - true_trajectory, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# ç»å¯¹è¯¯å·®\n",
    "axes[0].semilogy(t_span, errors)\n",
    "axes[0].set_xlabel('æ—¶é—´ t')\n",
    "axes[0].set_ylabel('L2 è¯¯å·®')\n",
    "axes[0].set_title('é¢„æµ‹è¯¯å·®éšæ—¶é—´å˜åŒ–')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ç›¸å¯¹è¯¯å·®\n",
    "true_norms = np.linalg.norm(true_trajectory, axis=1)\n",
    "relative_errors = errors / (true_norms + 1e-8)\n",
    "axes[1].semilogy(t_span, relative_errors)\n",
    "axes[1].set_xlabel('æ—¶é—´ t')\n",
    "axes[1].set_ylabel('ç›¸å¯¹è¯¯å·®')\n",
    "axes[1].set_title('ç›¸å¯¹è¯¯å·®éšæ—¶é—´å˜åŒ–')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "print(f\"åˆå§‹è¯¯å·®: {errors[0]:.6e}\")\n",
    "print(f\"æœ€ç»ˆè¯¯å·®: {errors[-1]:.4f}\")\n",
    "print(f\"å¹³å‡è¯¯å·®: {np.mean(errors):.4f}\")\n",
    "print(f\"é¢„æµ‹æ—¶é—´è·¨åº¦: {t_span[-1]:.2f} æ—¶é—´å•ä½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c6e569",
   "metadata": {},
   "source": [
    "## 5. ç¤ºä¾‹2: ä¸€ç»´çƒ­ä¼ å¯¼æ–¹ç¨‹ (PDE)\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å±•ç¤ºå¦‚ä½•ç”¨ Flow Map å­¦ä¹  PDE çš„æ—¶é—´æ¼”åŒ–ã€‚è€ƒè™‘ä¸€ç»´çƒ­ä¼ å¯¼æ–¹ç¨‹ï¼š\n",
    "\n",
    "$$\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}$$\n",
    "\n",
    "è¾¹ç•Œæ¡ä»¶ï¼š$u(0,t) = u(L,t) = 0$ï¼ˆDirichletè¾¹ç•Œï¼‰\n",
    "\n",
    "å¯¹äº PDEï¼Œæˆ‘ä»¬ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œæ¥å­¦ä¹ åœºçš„æ—¶é—´æ¼”åŒ–ï¼š$u(x, t+\\Delta t) = \\Phi_{\\Delta t}(u(x, t))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9982c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ PDE ç”¨çš„ Flow Map CNN\n",
    "class FlowMapCNN(nn.Module):\n",
    "    \"\"\"ç”¨äº PDE åœºæ¼”åŒ–çš„ Flow Map å·ç§¯ç½‘ç»œ\"\"\"\n",
    "    def __init__(self, n_channels=1, hidden_channels=32, kernel_size=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        padding = kernel_size // 2\n",
    "        \n",
    "        # å·ç§¯å±‚ï¼ˆä¿æŒç©ºé—´å°ºå¯¸ä¸å˜ï¼‰\n",
    "        self.conv1 = nn.Conv1d(n_channels + 1, hidden_channels, kernel_size, padding=padding)\n",
    "        self.conv2 = nn.Conv1d(hidden_channels, hidden_channels, kernel_size, padding=padding)\n",
    "        self.conv3 = nn.Conv1d(hidden_channels, hidden_channels, kernel_size, padding=padding)\n",
    "        self.conv4 = nn.Conv1d(hidden_channels, n_channels, kernel_size, padding=padding)\n",
    "        \n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "    def forward(self, u, dt):\n",
    "        \"\"\"\n",
    "        u: (batch, n_points) - å½“å‰åœº\n",
    "        dt: æ ‡é‡ - æ—¶é—´æ­¥é•¿\n",
    "        \"\"\"\n",
    "        batch_size, n_points = u.shape\n",
    "        \n",
    "        # æ·»åŠ é€šé“ç»´åº¦: (batch, 1, n_points)\n",
    "        x = u.unsqueeze(1)\n",
    "        \n",
    "        # åˆ›å»ºæ—¶é—´é€šé“\n",
    "        dt_channel = torch.ones(batch_size, 1, n_points, device=u.device) * dt\n",
    "        \n",
    "        # æ‹¼æ¥: (batch, 2, n_points)\n",
    "        x = torch.cat([x, dt_channel], dim=1)\n",
    "        \n",
    "        # å·ç§¯ç½‘ç»œ\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.activation(self.conv3(x))\n",
    "        residual = self.conv4(x)\n",
    "        \n",
    "        # æ®‹å·®è¿æ¥\n",
    "        u_next = u + residual.squeeze(1)\n",
    "        \n",
    "        return u_next\n",
    "    \n",
    "    def multi_step_predict(self, u0, dt, n_steps):\n",
    "        \"\"\"å¤šæ­¥é¢„æµ‹\"\"\"\n",
    "        trajectory = [u0]\n",
    "        u = u0\n",
    "        for _ in range(n_steps - 1):\n",
    "            u = self.forward(u, dt)\n",
    "            trajectory.append(u)\n",
    "        return torch.stack(trajectory, dim=1)\n",
    "\n",
    "print(\"FlowMapCNN æ¨¡å‹å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd2a8d",
   "metadata": {},
   "source": [
    "### 5.1 ç”Ÿæˆçƒ­ä¼ å¯¼æ–¹ç¨‹æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_equation_1d(n_x=64, L=1.0, alpha=0.01, dt=0.001, n_steps=100):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨æœ‰é™å·®åˆ†æ³•æ±‚è§£ä¸€ç»´çƒ­ä¼ å¯¼æ–¹ç¨‹\n",
    "    è¿”å›: xç½‘æ ¼, æ—¶é—´åºåˆ—, è§£çš„æ¼”åŒ–\n",
    "    \"\"\"\n",
    "    dx = L / (n_x - 1)\n",
    "    x = np.linspace(0, L, n_x)\n",
    "    \n",
    "    # ç¨³å®šæ€§æ¡ä»¶æ£€æŸ¥\n",
    "    r = alpha * dt / dx**2\n",
    "    if r > 0.5:\n",
    "        print(f\"è­¦å‘Š: ç¨³å®šæ€§å‚æ•° r={r:.3f} > 0.5ï¼Œå¯èƒ½ä¸ç¨³å®šï¼\")\n",
    "    \n",
    "    # åˆå§‹æ¡ä»¶: sin æ³¢\n",
    "    u0 = np.sin(2 * np.pi * x)\n",
    "    \n",
    "    # æ—¶é—´æ¼”åŒ–\n",
    "    u_history = [u0]\n",
    "    u = u0.copy()\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        u_new = u.copy()\n",
    "        # å†…éƒ¨ç‚¹ä½¿ç”¨ä¸­å¿ƒå·®åˆ†\n",
    "        u_new[1:-1] = u[1:-1] + r * (u[2:] - 2*u[1:-1] + u[:-2])\n",
    "        # Dirichlet è¾¹ç•Œæ¡ä»¶\n",
    "        u_new[0] = 0\n",
    "        u_new[-1] = 0\n",
    "        u = u_new\n",
    "        u_history.append(u.copy())\n",
    "    \n",
    "    return x, np.arange(n_steps + 1) * dt, np.array(u_history)\n",
    "\n",
    "# ç”Ÿæˆè®­ç»ƒæ•°æ®\n",
    "def generate_heat_training_data(n_samples=200, n_x=64):\n",
    "    \"\"\"ç”Ÿæˆå¤šä¸ªä¸åŒåˆå§‹æ¡ä»¶çš„çƒ­ä¼ å¯¼æ•°æ®\"\"\"\n",
    "    U_current = []\n",
    "    U_next = []\n",
    "    \n",
    "    L = 1.0\n",
    "    alpha = 0.01\n",
    "    dt_pde = 0.01  # å¤§ä¸€ç‚¹çš„ dt æ–¹ä¾¿è®­ç»ƒ\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # éšæœºåˆå§‹æ¡ä»¶: éšæœºé¢‘ç‡çš„æ­£å¼¦æ³¢ç»„åˆ\n",
    "        x = np.linspace(0, L, n_x)\n",
    "        k1, k2 = np.random.randint(1, 5, size=2)\n",
    "        a1, a2 = np.random.uniform(0.5, 1.5, size=2)\n",
    "        u0 = a1 * np.sin(k1 * np.pi * x) + a2 * np.sin(k2 * np.pi * x)\n",
    "        \n",
    "        # æ¼”åŒ–ä¸€æ­¥ï¼ˆä½¿ç”¨æ›´ç»†çš„æ—¶é—´æ­¥é•¿ä¿è¯ç²¾åº¦ï¼‰\n",
    "        n_substeps = 100\n",
    "        dt_sub = dt_pde / n_substeps\n",
    "        dx = L / (n_x - 1)\n",
    "        r = alpha * dt_sub / dx**2\n",
    "        \n",
    "        u = u0.copy()\n",
    "        for _ in range(n_substeps):\n",
    "            u_new = u.copy()\n",
    "            u_new[1:-1] = u[1:-1] + r * (u[2:] - 2*u[1:-1] + u[:-2])\n",
    "            u_new[0] = 0\n",
    "            u_new[-1] = 0\n",
    "            u = u_new\n",
    "        \n",
    "        U_current.append(u0)\n",
    "        U_next.append(u)\n",
    "    \n",
    "    return np.array(U_current), np.array(U_next), dt_pde\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "U_current, U_next, dt_pde = generate_heat_training_data(n_samples=500, n_x=64)\n",
    "print(f\"PDE è®­ç»ƒæ•°æ®å½¢çŠ¶: U_current={U_current.shape}, U_next={U_next.shape}\")\n",
    "print(f\"æ—¶é—´æ­¥é•¿: dt = {dt_pde}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65214fcb",
   "metadata": {},
   "source": [
    "### 5.2 è®­ç»ƒ FlowMapCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08547fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡†å¤‡æ•°æ®\n",
    "U_train = torch.FloatTensor(U_current)\n",
    "U_target = torch.FloatTensor(U_next)\n",
    "\n",
    "dataset_pde = TensorDataset(U_train, U_target)\n",
    "dataloader_pde = DataLoader(dataset_pde, batch_size=64, shuffle=True)\n",
    "\n",
    "# åˆå§‹åŒ– CNN æ¨¡å‹\n",
    "cnn_model = FlowMapCNN(n_channels=1, hidden_channels=32, kernel_size=5)\n",
    "optimizer_cnn = torch.optim.Adam(cnn_model.parameters(), lr=1e-3)\n",
    "criterion_cnn = nn.MSELoss()\n",
    "\n",
    "# è®­ç»ƒ\n",
    "n_epochs_pde = 300\n",
    "losses_pde = []\n",
    "\n",
    "for epoch in range(n_epochs_pde):\n",
    "    epoch_loss = 0.0\n",
    "    for U_batch, Y_batch in dataloader_pde:\n",
    "        optimizer_cnn.zero_grad()\n",
    "        \n",
    "        Y_pred = cnn_model(U_batch, dt_pde)\n",
    "        loss = criterion_cnn(Y_pred, Y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_cnn.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader_pde)\n",
    "    losses_pde.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs_pde}, Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee502f",
   "metadata": {},
   "source": [
    "### 5.3 PDE é•¿æœŸé¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf17da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”ŸæˆçœŸå®çš„ PDE æ¼”åŒ–ä½œä¸ºå‚è€ƒ\n",
    "x_pde, t_pde, u_true = heat_equation_1d(n_x=64, n_steps=100, dt=0.001)\n",
    "# æ¯10æ­¥å–ä¸€ä¸ªä½œä¸ºå¤§æ—¶é—´æ­¥\n",
    "u_true_coarse = u_true[::10]  # æ¯ dt_pde=0.01 å–ä¸€ä¸ª\n",
    "t_coarse = np.arange(len(u_true_coarse)) * dt_pde\n",
    "\n",
    "# Flow Map é¢„æµ‹\n",
    "cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    u0_tensor = torch.FloatTensor(u_true[0]).unsqueeze(0)\n",
    "    n_pred_steps = len(u_true_coarse)\n",
    "    u_pred = cnn_model.multi_step_predict(u0_tensor, dt_pde, n_pred_steps)\n",
    "    u_pred = u_pred.squeeze().numpy()\n",
    "\n",
    "print(f\"çœŸå®è§£å½¢çŠ¶: {u_true_coarse.shape}\")\n",
    "print(f\"é¢„æµ‹è§£å½¢çŠ¶: {u_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– PDE æ¼”åŒ–å¯¹æ¯”\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# çœŸå®è§£çš„æ—¶ç©ºå›¾\n",
    "im0 = axes[0].imshow(u_true_coarse, aspect='auto', origin='lower',\n",
    "                      extent=[0, 1, 0, t_coarse[-1]], cmap='RdBu_r')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('t')\n",
    "axes[0].set_title('çœŸå®è§£ (æœ‰é™å·®åˆ†)')\n",
    "plt.colorbar(im0, ax=axes[0])\n",
    "\n",
    "# é¢„æµ‹è§£çš„æ—¶ç©ºå›¾\n",
    "im1 = axes[1].imshow(u_pred, aspect='auto', origin='lower',\n",
    "                      extent=[0, 1, 0, t_coarse[-1]], cmap='RdBu_r')\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('t')\n",
    "axes[1].set_title('Flow Map é¢„æµ‹')\n",
    "plt.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# è¯¯å·®å›¾\n",
    "error = np.abs(u_pred - u_true_coarse)\n",
    "im2 = axes[2].imshow(error, aspect='auto', origin='lower',\n",
    "                      extent=[0, 1, 0, t_coarse[-1]], cmap='hot')\n",
    "axes[2].set_xlabel('x')\n",
    "axes[2].set_ylabel('t')\n",
    "axes[2].set_title('ç»å¯¹è¯¯å·®')\n",
    "plt.colorbar(im2, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08701e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å®šæ—¶åˆ»çš„å‰–é¢å¯¹æ¯”\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 6))\n",
    "\n",
    "time_indices = [0, 3, 6, 9, 10, -1]\n",
    "for idx, (ax, t_idx) in enumerate(zip(axes.flat, time_indices)):\n",
    "    ax.plot(x_pde, u_true_coarse[t_idx], 'b-', linewidth=2, label='çœŸå®')\n",
    "    ax.plot(x_pde, u_pred[t_idx], 'r--', linewidth=2, label='é¢„æµ‹')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('u')\n",
    "    ax.set_title(f't = {t_coarse[t_idx]:.3f}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('çƒ­ä¼ å¯¼æ–¹ç¨‹: ä¸åŒæ—¶åˆ»çš„è§£å‰–é¢', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017caeb0",
   "metadata": {},
   "source": [
    "## 6. Flow Map æ–¹æ³•çš„ä¼˜åŠ¿ä¸å±€é™\n",
    "\n",
    "### ä¼˜åŠ¿\n",
    "1. **é«˜æ•ˆé•¿æœŸé¢„æµ‹**: ä¸€æ¬¡è®­ç»ƒåå¯å¿«é€Ÿè¿›è¡Œå¤šæ­¥é¢„æµ‹\n",
    "2. **æ—¶é—´æ­¥é•¿çµæ´»**: å¯ä»¥å­¦ä¹ ä¸åŒå¤§å°çš„æ—¶é—´æ­¥\n",
    "3. **è‡ªç„¶ä¿æŒç»“æ„**: æ®‹å·®è¿æ¥å¤©ç„¶ä¿æŒè§£çš„ç‰©ç†ç‰¹æ€§\n",
    "4. **é€‚åˆé›†æˆå­¦ä¹ **: å¯ä»¥ç”¨é›†æˆæ–¹æ³•æé«˜é¢„æµ‹ç¨³å®šæ€§\n",
    "\n",
    "### å±€é™\n",
    "1. **éœ€è¦è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®**: éœ€è¦å®Œæ•´çš„è½¨è¿¹æ•°æ®å¯¹\n",
    "2. **è¯¯å·®ç´¯ç§¯**: é•¿æœŸé¢„æµ‹ä¸­è¯¯å·®ä¼šç´¯ç§¯\n",
    "3. **å¯¹æ··æ²Œç³»ç»Ÿ**: é¢„æµ‹æ—¶é—´æœ‰é™ï¼ˆå— Lyapunov æŒ‡æ•°é™åˆ¶ï¼‰\n",
    "4. **æ³›åŒ–æ€§**: å¯¹è¶…å‡ºè®­ç»ƒåˆ†å¸ƒçš„åˆå§‹æ¡ä»¶æ³›åŒ–æœ‰é™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f9218",
   "metadata": {},
   "source": [
    "## 7. ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”\n",
    "\n",
    "| æ–¹æ³• | è®­ç»ƒæ•°æ® | é¢„æµ‹æ–¹å¼ | ç‰©ç†çº¦æŸ | é€‚ç”¨åœºæ™¯ |\n",
    "|------|----------|----------|----------|----------|\n",
    "| **Flow Map** | è½¨è¿¹æ•°æ®å¯¹ | è‡ªå›å½’å±•å¼€ | æ®‹å·®ç»“æ„ | é•¿æœŸæ—¶é—´æ¼”åŒ– |\n",
    "| **PINNs** | è¾¹ç•Œ/åˆå§‹æ¡ä»¶ | ç›´æ¥æ±‚è§£ | PDE æ–¹ç¨‹ | æ­£/é€†é—®é¢˜ |\n",
    "| **DeepONet** | è¾“å…¥-è¾“å‡ºå‡½æ•°å¯¹ | å•æ¬¡å‰å‘ | å¯é€‰ | ç®—å­å­¦ä¹  |\n",
    "| **FNO** | è¾“å…¥-è¾“å‡ºå¯¹ | å•æ¬¡å‰å‘ | é¢‘åŸŸç»“æ„ | å¿«é€Ÿæ¨ç† |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac3711",
   "metadata": {},
   "source": [
    "## 8. å‚è€ƒæ–‡çŒ®\n",
    "\n",
    "1. **Flow Map Learning**:\n",
    "   - Qin, Tengfei, et al. \"Data-driven learning of non-autonomous systems.\" *Science China Mathematics* (2019)\n",
    "   - Chen, Zhen, and Dongbin Xiu. \"On generalized residual network for deep learning of unknown dynamical systems.\" *Journal of Computational Physics* 438 (2021)\n",
    "\n",
    "2. **Neural ODEs ç›¸å…³**:\n",
    "   - Chen, Ricky TQ, et al. \"Neural ordinary differential equations.\" *NeurIPS* (2018)\n",
    "\n",
    "3. **ç›¸å…³æ–¹æ³•**:\n",
    "   - Raissi, Maziar, et al. \"Physics-informed neural networks.\" *Journal of Computational Physics* 378 (2019)\n",
    "   - Li, Zongyi, et al. \"Fourier neural operator.\" *ICLR* (2021)\n",
    "\n",
    "---\n",
    "**æ•™ç¨‹å®Œæˆï¼** \n",
    "\n",
    "ç°åœ¨ä½ å·²ç»å­¦ä¼šäº†ï¼š\n",
    "- âœ… Flow Map çš„æ ¸å¿ƒæ¦‚å¿µå’Œæ•°å­¦åŸç†\n",
    "- âœ… å¦‚ä½•æ„å»º FlowMapMLP å’Œ FlowMapCNN\n",
    "- âœ… åº”ç”¨äº ODE (Lorenz ç³»ç»Ÿ)\n",
    "- âœ… åº”ç”¨äº PDE (çƒ­ä¼ å¯¼æ–¹ç¨‹)\n",
    "- âœ… è¯¯å·®åˆ†æå’Œå¯è§†åŒ–\n",
    "\n",
    "æ›´å¤šç¤ºä¾‹è¯·å‚è€ƒ `examples/` æ–‡ä»¶å¤¹ï¼"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
