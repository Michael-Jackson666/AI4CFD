"""
ç®—å­å­¦ä¹ å®Œæ•´è®­ç»ƒä»£ç  - çº¯PyTorchå®ç°
Deep Operator Network (DeepONet) for Integral Operator Learning

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„DeepONetå®ç°ï¼Œç”¨äºå­¦ä¹ ç§¯åˆ†ç®—å­æ˜ å°„ã€‚
è¿è¡Œæ­¤æ–‡ä»¶å³å¯å®Œæˆæ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œå¯è§†åŒ–ã€‚

ä½œè€…: AI4CFDå›¢é˜Ÿ
æ—¥æœŸ: 2025å¹´10æœˆ11æ—¥
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
import os
import json
from datetime import datetime

warnings.filterwarnings('ignore')

# è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
torch.manual_seed(42)
np.random.seed(42)

# è®¾å¤‡é€‰æ‹©
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
print(f"ğŸ”¥ PyTorchç‰ˆæœ¬: {torch.__version__}")

# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('seaborn-v0_8')

# ==================== æ¨¡å‹å®šä¹‰ ====================

class MLP(nn.Module):
    """å¤šå±‚æ„ŸçŸ¥æœºåŸºç¡€ç±»"""
    
    def __init__(self, input_dim, hidden_dims, output_dim, activation='tanh'):
        super(MLP, self).__init__()
        
        # é€‰æ‹©æ¿€æ´»å‡½æ•°
        if activation == 'tanh':
            self.activation = nn.Tanh()
        elif activation == 'relu':
            self.activation = nn.ReLU()
        elif activation == 'swish':
            self.activation = nn.SiLU()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¿€æ´»å‡½æ•°: {activation}")
        
        # æ„å»ºç½‘ç»œå±‚
        layers = []
        dims = [input_dim] + hidden_dims + [output_dim]
        
        for i in range(len(dims) - 1):
            layers.append(nn.Linear(dims[i], dims[i+1]))
            # é™¤äº†æœ€åä¸€å±‚ï¼Œéƒ½æ·»åŠ æ¿€æ´»å‡½æ•°
            if i < len(dims) - 2:
                layers.append(self.activation)
        
        self.network = nn.Sequential(*layers)
        
        # åˆå§‹åŒ–æƒé‡
        self.init_weights()
    
    def init_weights(self):
        """Xavierå‡åŒ€åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                nn.init.zeros_(m.bias)
    
    def forward(self, x):
        return self.network(x)


class SimpleDeepONet(nn.Module):
    """ç®€åŒ–ç‰ˆDeepONetå®ç°"""
    
    def __init__(self, n_sensors, coord_dim, hidden_dim=100, latent_dim=100):
        super(SimpleDeepONet, self).__init__()
        
        self.n_sensors = n_sensors
        self.coord_dim = coord_dim
        self.latent_dim = latent_dim
        
        # åˆ†æ”¯ç½‘ç»œï¼šå¤„ç†ä¼ æ„Ÿå™¨æ•°æ®
        self.branch_net = MLP(
            input_dim=n_sensors,
            hidden_dims=[hidden_dim, hidden_dim, hidden_dim],
            output_dim=latent_dim
        )
        
        # ä¸»å¹²ç½‘ç»œï¼šå¤„ç†æŸ¥è¯¢åæ ‡
        self.trunk_net = MLP(
            input_dim=coord_dim,
            hidden_dims=[hidden_dim, hidden_dim, hidden_dim],
            output_dim=latent_dim
        )
        
        # åç½®é¡¹
        self.bias = nn.Parameter(torch.zeros(1))
        
        print(f"ğŸ—ï¸ DeepONetæ¨¡å‹åˆ›å»ºå®Œæˆ:")
        print(f"   ğŸ“¡ ä¼ æ„Ÿå™¨æ•°é‡: {n_sensors}")
        print(f"   ğŸ“ åæ ‡ç»´åº¦: {coord_dim}")
        print(f"   ğŸ§  æ½œåœ¨ç©ºé—´ç»´åº¦: {latent_dim}")
        print(f"   ğŸ”¢ æ€»å‚æ•°æ•°: {sum(p.numel() for p in self.parameters()):,}")
    
    def forward(self, sensor_data, query_coords):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            sensor_data: ä¼ æ„Ÿå™¨æ•°æ® [batch_size, n_sensors]
            query_coords: æŸ¥è¯¢åæ ‡ [batch_size, n_queries, coord_dim]
        
        Returns:
            output: é¢„æµ‹ç»“æœ [batch_size, n_queries, 1]
        """
        batch_size = sensor_data.shape[0]
        n_queries = query_coords.shape[1]
        
        # åˆ†æ”¯ç½‘ç»œè¾“å‡º: [batch_size, latent_dim]
        branch_output = self.branch_net(sensor_data)
        
        # ä¸»å¹²ç½‘ç»œè¾“å‡º: [batch_size * n_queries, latent_dim]
        coords_flat = query_coords.view(-1, self.coord_dim)
        trunk_output = self.trunk_net(coords_flat)
        trunk_output = trunk_output.view(batch_size, n_queries, self.latent_dim)
        
        # è®¡ç®—å†…ç§¯: [batch_size, n_queries]
        output = torch.einsum('bl,bql->bq', branch_output, trunk_output)
        
        # æ·»åŠ åç½®å¹¶æ‰©å±•ç»´åº¦: [batch_size, n_queries, 1]
        output = output + self.bias
        output = output.unsqueeze(-1)
        
        return output


# ==================== æ•°æ®ç”Ÿæˆå™¨ ====================

class IntegralOperatorDataset:
    """ç§¯åˆ†ç®—å­æ•°æ®é›†"""
    
    def __init__(self, n_samples=1000, n_sensors=50, n_queries=100, domain=[0, 1]):
        self.n_samples = n_samples
        self.n_sensors = n_sensors
        self.n_queries = n_queries
        self.domain = domain
        
        # ä¼ æ„Ÿå™¨ä½ç½®ï¼ˆå›ºå®šï¼‰
        self.sensor_locations = torch.linspace(domain[0], domain[1], n_sensors)
        
        print(f"ğŸ“Š åˆ›å»ºç§¯åˆ†ç®—å­æ•°æ®é›†:")
        print(f"   ğŸ“ˆ æ ·æœ¬æ•°é‡: {n_samples}")
        print(f"   ğŸ“¡ ä¼ æ„Ÿå™¨æ•°é‡: {n_sensors}")
        print(f"   ğŸ“ æŸ¥è¯¢ç‚¹æ•°é‡: {n_queries}")
        print(f"   ğŸ”¢ å®šä¹‰åŸŸ: {domain}")
    
    def generate_input_function(self, coeffs):
        """
        ç”Ÿæˆè¾“å…¥å‡½æ•° u(x) = Î£ a_k sin(k*Ï€*x)
        
        Args:
            coeffs: å‚…é‡Œå¶ç³»æ•° [n_modes]
            
        Returns:
            function: åœ¨ä¼ æ„Ÿå™¨ä½ç½®çš„å‡½æ•°å€¼
        """
        x = self.sensor_locations
        u = torch.zeros_like(x)
        
        for k, a_k in enumerate(coeffs, 1):
            u += a_k * torch.sin(k * np.pi * x)
        
        return u
    
    def compute_integral(self, coeffs, query_points):
        """
        è®¡ç®—ç§¯åˆ†ç®—å­çš„è§£æè§£
        G[u](y) = âˆ«â‚€Ê¸ u(x) dx
        
        For u(x) = Î£ a_k sin(k*Ï€*x), the integral is:
        G[u](y) = Î£ a_k * (1 - cos(k*Ï€*y)) / (k*Ï€)
        """
        integral_values = torch.zeros_like(query_points)
        
        for k, a_k in enumerate(coeffs, 1):
            integral_values += a_k * (1 - torch.cos(k * np.pi * query_points)) / (k * np.pi)
        
        return integral_values
    
    def generate_data(self):
        """ç”Ÿæˆè®­ç»ƒæ•°æ®"""
        
        sensor_data = []
        query_coords = []
        target_values = []
        
        print("ğŸ”„ å¼€å§‹ç”Ÿæˆæ•°æ®...")
        for i in tqdm(range(self.n_samples), desc="ç”Ÿæˆæ•°æ®"):
            # éšæœºç”Ÿæˆå‚…é‡Œå¶ç³»æ•°
            coeffs = torch.randn(5) * 0.5  # 5ä¸ªæ¨¡æ€
            
            # ç”Ÿæˆè¾“å…¥å‡½æ•°åœ¨ä¼ æ„Ÿå™¨ä½ç½®çš„å€¼
            u_sensors = self.generate_input_function(coeffs)
            sensor_data.append(u_sensors)
            
            # éšæœºé€‰æ‹©æŸ¥è¯¢ç‚¹
            query_points = torch.rand(self.n_queries) * (self.domain[1] - self.domain[0]) + self.domain[0]
            query_points = query_points.sort()[0]  # æ’åºä»¥ä¾¿å¯è§†åŒ–
            query_coords.append(query_points.unsqueeze(-1))
            
            # è®¡ç®—ç§¯åˆ†ç®—å­çš„ç²¾ç¡®å€¼
            integral_exact = self.compute_integral(coeffs, query_points)
            target_values.append(integral_exact.unsqueeze(-1))
        
        # è½¬æ¢ä¸ºå¼ é‡
        sensor_data = torch.stack(sensor_data)
        query_coords = torch.stack(query_coords)
        target_values = torch.stack(target_values)
        
        print(f"\nâœ… æ•°æ®ç”Ÿæˆå®Œæˆ!")
        print(f"   ğŸ“Š ä¼ æ„Ÿå™¨æ•°æ®å½¢çŠ¶: {sensor_data.shape}")
        print(f"   ğŸ“ æŸ¥è¯¢åæ ‡å½¢çŠ¶: {query_coords.shape}")
        print(f"   ğŸ¯ ç›®æ ‡å€¼å½¢çŠ¶: {target_values.shape}")
        
        return sensor_data, query_coords, target_values


# ==================== è®­ç»ƒå™¨ ====================

class DeepONetTrainer:
    """DeepONetè®­ç»ƒå™¨"""
    
    def __init__(self, model, device='cpu', save_dir='./results'):
        self.model = model.to(device)
        self.device = device
        self.history = {'train_loss': [], 'val_loss': []}
        self.save_dir = save_dir
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
    
    def train(self, sensor_data, query_coords, target_values, 
              epochs=5000, batch_size=32, lr=1e-3, val_split=0.2,
              save_model=True, plot_interval=1000):
        """è®­ç»ƒæ¨¡å‹"""
        
        print(f"\nğŸš€ å¼€å§‹DeepONetè®­ç»ƒ...")
        print(f"   ğŸ“Š è®­ç»ƒè½®æ¬¡: {epochs}")
        print(f"   ğŸ¯ æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"   ğŸ“ˆ å­¦ä¹ ç‡: {lr}")
        print(f"   ğŸ”„ éªŒè¯é›†æ¯”ä¾‹: {val_split}")
        
        # æ•°æ®åˆ†å‰²
        n_samples = sensor_data.shape[0]
        n_val = int(n_samples * val_split)
        n_train = n_samples - n_val
        
        indices = torch.randperm(n_samples)
        train_idx, val_idx = indices[:n_train], indices[n_train:]
        
        train_sensor = sensor_data[train_idx].to(self.device)
        train_coords = query_coords[train_idx].to(self.device)
        train_targets = target_values[train_idx].to(self.device)
        
        val_sensor = sensor_data[val_idx].to(self.device)
        val_coords = query_coords[val_idx].to(self.device)
        val_targets = target_values[val_idx].to(self.device)
        
        print(f"ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ:")
        print(f"   ğŸš‚ è®­ç»ƒé›†: {n_train} æ ·æœ¬")
        print(f"   ğŸ” éªŒè¯é›†: {n_val} æ ·æœ¬")
        
        # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        optimizer = optim.Adam(self.model.parameters(), lr=lr)
        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)
        criterion = nn.MSELoss()
        
        best_val_loss = float('inf')
        
        # è®­ç»ƒå¾ªç¯
        print(f"\nğŸ”¥ å¼€å§‹è®­ç»ƒå¾ªç¯...")
        for epoch in tqdm(range(epochs), desc="è®­ç»ƒè¿›åº¦"):
            # è®­ç»ƒé˜¶æ®µ
            self.model.train()
            train_loss = 0.0
            
            # æ‰¹æ¬¡è®­ç»ƒ
            n_batches = (n_train + batch_size - 1) // batch_size
            for batch_idx in range(n_batches):
                start_idx = batch_idx * batch_size
                end_idx = min((batch_idx + 1) * batch_size, n_train)
                
                batch_sensor = train_sensor[start_idx:end_idx]
                batch_coords = train_coords[start_idx:end_idx]
                batch_targets = train_targets[start_idx:end_idx]
                
                optimizer.zero_grad()
                
                # å‰å‘ä¼ æ’­
                predictions = self.model(batch_sensor, batch_coords)
                loss = criterion(predictions, batch_targets)
                
                # åå‘ä¼ æ’­
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
            
            train_loss /= n_batches
            
            # éªŒè¯é˜¶æ®µ
            self.model.eval()
            with torch.no_grad():
                val_predictions = self.model(val_sensor, val_coords)
                val_loss = criterion(val_predictions, val_targets).item()
            
            # è®°å½•å†å²
            self.history['train_loss'].append(train_loss)
            self.history['val_loss'].append(val_loss)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < best_val_loss and save_model:
                best_val_loss = val_loss
                self.save_checkpoint(epoch, val_loss, 'best_model.pth')
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()
            
            # æ‰“å°è¿›åº¦
            if (epoch + 1) % plot_interval == 0:
                print(f"\nè½®æ¬¡ {epoch+1:4d}/{epochs}: "
                      f"è®­ç»ƒæŸå¤± = {train_loss:.6e}, "
                      f"éªŒè¯æŸå¤± = {val_loss:.6e}, "
                      f"å­¦ä¹ ç‡ = {optimizer.param_groups[0]['lr']:.1e}")
        
        print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"   ğŸ“‰ æœ€ç»ˆè®­ç»ƒæŸå¤±: {self.history['train_loss'][-1]:.6e}")
        print(f"   ğŸ“Š æœ€ç»ˆéªŒè¯æŸå¤±: {self.history['val_loss'][-1]:.6e}")
        print(f"   ğŸ† æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6e}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹å’Œè®­ç»ƒå†å²
        if save_model:
            self.save_checkpoint(epochs-1, self.history['val_loss'][-1], 'final_model.pth')
            self.save_training_history()
        
        return self.history
    
    def save_checkpoint(self, epoch, loss, filename):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'loss': loss,
            'history': self.history,
            'timestamp': datetime.now().isoformat()
        }
        torch.save(checkpoint, os.path.join(self.save_dir, filename))
    
    def save_training_history(self):
        """ä¿å­˜è®­ç»ƒå†å²"""
        history_path = os.path.join(self.save_dir, 'training_history.json')
        with open(history_path, 'w') as f:
            json.dump(self.history, f, indent=2)
    
    def plot_training_history(self, save_plot=True):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        
        epochs = range(1, len(self.history['train_loss']) + 1)
        ax.semilogy(epochs, self.history['train_loss'], 'b-', linewidth=2, label='è®­ç»ƒæŸå¤±')
        ax.semilogy(epochs, self.history['val_loss'], 'r-', linewidth=2, label='éªŒè¯æŸå¤±')
        
        ax.set_xlabel('è®­ç»ƒè½®æ¬¡')
        ax.set_ylabel('æŸå¤±å€¼ (å¯¹æ•°å°ºåº¦)')
        ax.set_title('DeepONetè®­ç»ƒå†å²', fontsize=14, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        if save_plot:
            plt.savefig(os.path.join(self.save_dir, 'training_history.png'), 
                       dpi=300, bbox_inches='tight')
        
        plt.tight_layout()
        plt.show()


# ==================== è¯„ä¼°å™¨ ====================

class ModelEvaluator:
    """æ¨¡å‹è¯„ä¼°å™¨"""
    
    def __init__(self, model, device, save_dir='./results'):
        self.model = model
        self.device = device
        self.save_dir = save_dir
    
    def evaluate_model(self, dataset, n_test_samples=100):
        """å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        
        print("ğŸ§ª ç”Ÿæˆæµ‹è¯•æ•°æ®...")
        test_sensor, test_coords, test_targets = dataset.generate_data()
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        test_sensor = test_sensor[:n_test_samples].to(self.device)
        test_coords = test_coords[:n_test_samples].to(self.device)
        test_targets = test_targets[:n_test_samples].to(self.device)
        
        # æ¨¡å‹é¢„æµ‹
        self.model.eval()
        with torch.no_grad():
            predictions = self.model(test_sensor, test_coords)
        
        # è®¡ç®—è¯¯å·®æŒ‡æ ‡
        mse = torch.mean((predictions - test_targets) ** 2).item()
        mae = torch.mean(torch.abs(predictions - test_targets)).item()
        relative_error = torch.mean(torch.abs(predictions - test_targets) / 
                                   (torch.abs(test_targets) + 1e-8)).item()
        
        # è®¡ç®—RÂ²
        pred_flat = predictions.cpu().numpy().flatten()
        target_flat = test_targets.cpu().numpy().flatten()
        r2 = 1 - np.sum((pred_flat - target_flat)**2) / np.sum((target_flat - target_flat.mean())**2)
        
        print(f"\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°:")
        print(f"   ğŸ“ˆ å‡æ–¹è¯¯å·® (MSE): {mse:.6e}")
        print(f"   ğŸ“ å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.6e}")
        print(f"   ğŸ“‹ ç›¸å¯¹è¯¯å·®: {relative_error:.6f}")
        print(f"   ğŸ¯ RÂ² ç³»æ•°: {r2:.6f}")
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        results = {
            'mse': mse,
            'mae': mae,
            'relative_error': relative_error,
            'r2_score': r2,
            'n_test_samples': n_test_samples
        }
        
        results_path = os.path.join(self.save_dir, 'evaluation_results.json')
        with open(results_path, 'w') as f:
            json.dump(results, f, indent=2)
        
        return predictions, test_targets, test_coords, test_sensor, results
    
    def visualize_predictions(self, predictions, targets, coords, sensor_data, 
                            dataset, n_samples=4, save_plot=True):
        """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
        
        # è½¬æ¢ä¸ºCPUå¹¶å–æ ·æœ¬
        pred_np = predictions[:n_samples].cpu().numpy()
        target_np = targets[:n_samples].cpu().numpy()
        coords_np = coords[:n_samples].cpu().numpy()
        sensor_np = sensor_data[:n_samples].cpu().numpy()
        
        # åˆ›å»ºå¤§å›¾
        fig = plt.figure(figsize=(20, 12))
        
        for i in range(n_samples):
            # è¾“å…¥å‡½æ•°
            ax1 = plt.subplot(3, n_samples, i + 1)
            ax1.plot(dataset.sensor_locations, sensor_np[i], 'ro-', 
                    markersize=4, linewidth=2, alpha=0.8)
            ax1.set_title(f'è¾“å…¥å‡½æ•° u_{i+1}(x)', fontweight='bold')
            ax1.set_xlabel('x')
            ax1.set_ylabel('u(x)')
            ax1.grid(True, alpha=0.3)
            
            # é¢„æµ‹ vs çœŸå®å€¼
            ax2 = plt.subplot(3, n_samples, i + 1 + n_samples)
            x_query = coords_np[i, :, 0]
            y_true = target_np[i, :, 0]
            y_pred = pred_np[i, :, 0]
            
            ax2.plot(x_query, y_true, 'b-', linewidth=3, label='çœŸå®å€¼', alpha=0.8)
            ax2.plot(x_query, y_pred, 'r--', linewidth=2, label='é¢„æµ‹å€¼')
            ax2.set_title(f'G[u_{i+1}] - é¢„æµ‹ vs çœŸå®', fontweight='bold')
            ax2.set_xlabel('x')
            ax2.set_ylabel('G[u](x)')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            # è¯¯å·®åˆ†æ
            ax3 = plt.subplot(3, n_samples, i + 1 + 2*n_samples)
            error = np.abs(y_pred - y_true)
            ax3.plot(x_query, error, 'g-', linewidth=2)
            ax3.fill_between(x_query, 0, error, alpha=0.3, color='green')
            ax3.set_title(f'ç»å¯¹è¯¯å·® |é¢„æµ‹ - çœŸå®|', fontweight='bold')
            ax3.set_xlabel('x')
            ax3.set_ylabel('|è¯¯å·®|')
            ax3.grid(True, alpha=0.3)
            
            # æ·»åŠ è¯¯å·®ç»Ÿè®¡
            mean_error = np.mean(error)
            max_error = np.max(error)
            ax3.text(0.05, 0.95, f'å¹³å‡: {mean_error:.4f}\næœ€å¤§: {max_error:.4f}', 
                    transform=ax3.transAxes, verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        if save_plot:
            plt.savefig(os.path.join(self.save_dir, 'prediction_results.png'), 
                       dpi=300, bbox_inches='tight')
        
        plt.tight_layout()
        plt.show()
    
    def final_demonstration(self, dataset, save_plot=True):
        """æœ€ç»ˆæ¼”ç¤ºï¼šæµ‹è¯•å…¨æ–°çš„é«˜æ–¯å‡½æ•°"""
        
        print("ğŸ­ æœ€ç»ˆæ¼”ç¤ºï¼šDeepONetå¤„ç†å…¨æ–°è¾“å…¥å‡½æ•°")
        print("="*50)
        
        # åˆ›å»ºæµ‹è¯•å‡½æ•°
        x = torch.linspace(0, 1, 50)
        
        def gaussian_function(x, center=0.5, width=0.2):
            return torch.exp(-((x - center) / width) ** 2)
        
        # ä¸‰ä¸ªä¸åŒçš„é«˜æ–¯å‡½æ•°
        test_functions = [
            gaussian_function(x, 0.3, 0.1),
            gaussian_function(x, 0.7, 0.15),
            gaussian_function(x, 0.5, 0.25)
        ]
        
        query_points = torch.linspace(0, 1, 100).unsqueeze(-1)
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        
        self.model.eval()
        for i, test_func in enumerate(test_functions):
            # å‡†å¤‡è¾“å…¥
            sensor_input = test_func.unsqueeze(0).to(self.device)
            query_input = query_points.unsqueeze(0).to(self.device)
            
            # DeepONeté¢„æµ‹
            with torch.no_grad():
                prediction = self.model(sensor_input, query_input)
            
            # æ•°å€¼ç§¯åˆ†ä½œä¸ºå‚è€ƒ
            x_fine = torch.linspace(0, 1, 1000)
            func_fine = gaussian_function(x_fine, 
                                        0.3 + i * 0.2, 
                                        0.1 + i * 0.075)
            numerical_integral = []
            for j, y in enumerate(query_points.squeeze()):
                mask = x_fine <= y
                if mask.sum() > 1:
                    integral_val = torch.trapz(func_fine[mask], x_fine[mask])
                else:
                    integral_val = torch.tensor(0.0)
                numerical_integral.append(integral_val)
            numerical_integral = torch.stack(numerical_integral)
            
            # ç»˜åˆ¶è¾“å…¥å‡½æ•°
            axes[0, i].plot(x, test_func, 'bo-', linewidth=2, markersize=3)
            axes[0, i].set_title(f'æµ‹è¯•å‡½æ•° {i+1} (é«˜æ–¯åˆ†å¸ƒ)', fontweight='bold')
            axes[0, i].set_xlabel('x')
            axes[0, i].set_ylabel('u(x)')
            axes[0, i].grid(True, alpha=0.3)
            
            # ç»˜åˆ¶ç§¯åˆ†é¢„æµ‹
            axes[1, i].plot(query_points.squeeze(), prediction.cpu().squeeze(), 
                           'r-', linewidth=3, label='DeepONeté¢„æµ‹')
            axes[1, i].plot(query_points.squeeze(), numerical_integral, 
                           'b--', linewidth=2, alpha=0.7, label='æ•°å€¼ç§¯åˆ†')
            axes[1, i].set_title(f'ç§¯åˆ†é¢„æµ‹ vs æ•°å€¼è§£', fontweight='bold')
            axes[1, i].set_xlabel('x')
            axes[1, i].set_ylabel('âˆ«â‚€Ë£ u(s) ds')
            axes[1, i].legend()
            axes[1, i].grid(True, alpha=0.3)
            
            # è®¡ç®—è¯¯å·®
            error = torch.abs(prediction.cpu().squeeze() - numerical_integral)
            mean_error = torch.mean(error).item()
            max_error = torch.max(error).item()
            
            print(f"æµ‹è¯•å‡½æ•° {i+1}: å¹³å‡è¯¯å·® = {mean_error:.6f}, æœ€å¤§è¯¯å·® = {max_error:.6f}")
        
        if save_plot:
            plt.savefig(os.path.join(self.save_dir, 'generalization_test.png'), 
                       dpi=300, bbox_inches='tight')
        
        plt.tight_layout()
        plt.show()
        
        print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼DeepONetæˆåŠŸå¤„ç†äº†è®­ç»ƒæ—¶æœªè§è¿‡çš„é«˜æ–¯å‡½æ•°ï¼")
        print("ğŸ’¡ è¿™è¯æ˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œç®—å­å­¦ä¹ çš„å¨åŠ›ã€‚")


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    
    print("="*60)
    print("ğŸš€ DeepONetç®—å­å­¦ä¹ è®­ç»ƒç¨‹åº")
    print("="*60)
    
    # é…ç½®å‚æ•°
    config = {
        'n_samples': 1000,
        'n_sensors': 50,
        'n_queries': 100,
        'hidden_dim': 64,
        'latent_dim': 64,
        'epochs': 3000,
        'batch_size': 16,
        'lr': 1e-3,
        'val_split': 0.2,
        'save_dir': './deeponet_results'
    }
    
    print("ğŸ“‹ è®­ç»ƒé…ç½®:")
    for key, value in config.items():
        print(f"   {key}: {value}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(config['save_dir'], exist_ok=True)
    
    # ä¿å­˜é…ç½®
    config_path = os.path.join(config['save_dir'], 'config.json')
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    # 1. åˆ›å»ºæ•°æ®é›†
    print("\n" + "="*40)
    print("ğŸ“Š Step 1: åˆ›å»ºæ•°æ®é›†")
    print("="*40)
    
    dataset = IntegralOperatorDataset(
        n_samples=config['n_samples'],
        n_sensors=config['n_sensors'],
        n_queries=config['n_queries']
    )
    
    sensor_data, query_coords, target_values = dataset.generate_data()
    
    # 2. åˆ›å»ºæ¨¡å‹
    print("\n" + "="*40)
    print("ğŸ—ï¸ Step 2: åˆ›å»ºDeepONetæ¨¡å‹")
    print("="*40)
    
    model = SimpleDeepONet(
        n_sensors=config['n_sensors'],
        coord_dim=1,
        hidden_dim=config['hidden_dim'],
        latent_dim=config['latent_dim']
    )
    
    # 3. è®­ç»ƒæ¨¡å‹
    print("\n" + "="*40)
    print("ğŸš€ Step 3: è®­ç»ƒæ¨¡å‹")
    print("="*40)
    
    trainer = DeepONetTrainer(model, device=device, save_dir=config['save_dir'])
    history = trainer.train(
        sensor_data=sensor_data,
        query_coords=query_coords,
        target_values=target_values,
        epochs=config['epochs'],
        batch_size=config['batch_size'],
        lr=config['lr'],
        val_split=config['val_split']
    )
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    trainer.plot_training_history()
    
    # 4. è¯„ä¼°æ¨¡å‹
    print("\n" + "="*40)
    print("ğŸ“Š Step 4: è¯„ä¼°æ¨¡å‹")
    print("="*40)
    
    evaluator = ModelEvaluator(model, device, save_dir=config['save_dir'])
    
    # æ ‡å‡†è¯„ä¼°
    predictions, targets, coords, sensor_test, results = evaluator.evaluate_model(dataset)
    
    # å¯è§†åŒ–é¢„æµ‹ç»“æœ
    evaluator.visualize_predictions(predictions, targets, coords, sensor_test, dataset)
    
    # æ³›åŒ–èƒ½åŠ›æµ‹è¯•
    evaluator.final_demonstration(dataset)
    
    print("\n" + "="*60)
    print("âœ… è®­ç»ƒæµç¨‹å®Œæˆï¼")
    print("="*60)
    print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {config['save_dir']}")
    print("ğŸ“Š æ–‡ä»¶åˆ—è¡¨:")
    for file in os.listdir(config['save_dir']):
        print(f"   - {file}")
    
    return model, history, results


if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    model, history, results = main()